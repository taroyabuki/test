{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colaboratory\u306e\u74b0\u5883\u8a2d\u5b9a\n",
        "import os\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "  !python -m pip install h2o pandarallel pca pmdarima prophet | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u3053\u308c\u306fPython\u306e\u30b3\u30fc\u30c9\u306e\u4f8b\u3067\u3059\uff0e\n",
        "1 + 1\n",
        "#> 2 # \u6ce8\u76ee\u3059\u3079\u304d\u5b9f\u884c\u7d50\u679c\u3067\u3059\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 + 1\n",
        "# 2 # \u3053\u308c\u306f\u8868\u793a\u3055\u308c\u306a\u3044\uff0e\n",
        "\n",
        "print(1 + 2)\n",
        "# 3 # \u8868\u793a\u3055\u308c\u308b\uff0e\n",
        "\n",
        "1 + 3\n",
        "# 4 # \u8868\u793a\u3055\u308c\u308b\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "0x10\n",
        "#> 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1.23e5\n",
        "#> 123000.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "2 * 3\n",
        "#> 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "10 / 3\n",
        "#> 3.3333333333333335"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "10 // 3 # \u5546\n",
        "#> 3\n",
        "\n",
        "10 % 3  # \u4f59\u308a\n",
        "#> 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 2\n",
        "y = 3\n",
        "x * y\n",
        "#> 6\n",
        "\n",
        "x, y = 20, 30 # \u307e\u3068\u3081\u3066\u540d\u4ed8\u3051\n",
        "x * y\n",
        "#> 600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 1 + 1\n",
        "# \u3053\u306e\u6bb5\u968e\u3067\u306f\u7d50\u679c\u306f\u8868\u793a\u3055\u308c\u306a\u3044\n",
        "\n",
        "x # \u5909\u6570\u540d\u3092\u8a55\u4fa1\u3059\u308b\uff0e\n",
        "#> 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_s = 'abcde'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(my_s)\n",
        "#> 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'This is' ' a' ' pen.'\n",
        "# \u3042\u308b\u3044\u306f\n",
        "'This is ' + 'a' + ' pen.'\n",
        "#> 'This is a pen.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_s[1:4]\n",
        "#> 'bcd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = \"{} is {}.\"\n",
        "tmp.format('This', 'a pen')\n",
        "#> 'This is a pen.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 <= 2\n",
        "#> True\n",
        "\n",
        "1 < 0\n",
        "#> False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "0.1 + 0.1 + 0.1 == 0.3\n",
        "#> False\n",
        "\n",
        "import math\n",
        "math.isclose(0.1 + 0.1 + 0.1, 0.3)\n",
        "#> True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "True and False # \u8ad6\u7406\u7a4d\uff08\u304b\u3064\uff09\n",
        "#> False\n",
        "\n",
        "True or False  # \u8ad6\u7406\u548c\uff08\u307e\u305f\u306f\uff09\n",
        "#> True\n",
        "\n",
        "not True       # \u5426\u5b9a\uff08\u3067\u306a\u3044\uff09\n",
        "#> False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "0 if 3 < 5 else 10\n",
        "#> 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "#> '/home/jovyan/work'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('..')\n",
        "os.getcwd()\n",
        "#> '/home/jovyan'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "math.sqrt(4)\n",
        "#> 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "math.log(100, 10)\n",
        "#> 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "math.log(100)         # \u81ea\u7136\u5bfe\u6570\n",
        "# \u3042\u308b\u3044\u306f\n",
        "math.log(100, math.e) # \u7701\u7565\u3057\u306a\u3044\u5834\u5408\n",
        "\n",
        "#> 4.605170185988092"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "math.log10(100) # \u5e38\u7528\u5bfe\u6570\n",
        "#> 2.0\n",
        "\n",
        "math.log2(1024) # \u5e95\u304c2\u306e\u5bfe\u6570\n",
        "#> 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(a, b):\n",
        "    return a - b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f(3, 5)\n",
        "#> -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(a, b=5):\n",
        "    return a - b\n",
        "\n",
        "f(3) # f(3, 5)\u3068\u540c\u3058\u3053\u3068\n",
        "#> -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(lambda a, b: a - b)(3, 5)\n",
        "#> -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = ['foo', 'bar', 'baz']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(x)\n",
        "#> 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x[1]\n",
        "#> 'bar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x[1] = 'BAR'\n",
        "x # \u7d50\u679c\u306e\u78ba\u8a8d\n",
        "#> ['foo', 'BAR', 'baz']\n",
        "\n",
        "x[1] = 'bar' # \u5143\u306b\u623b\u3059\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x[-2]\n",
        "#> 'bar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x + ['qux']\n",
        "#> ['foo', 'bar', 'baz', 'qux']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = x + ['qux']\n",
        "# \u3042\u308b\u3044\u306f\n",
        "#x.append('qux')\n",
        "\n",
        "x # \u7d50\u679c\u306e\u78ba\u8a8d\n",
        "#> ['foo', 'bar', 'baz', 'qux']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(range(5))\n",
        "#> [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(range(0, 11, 2))\n",
        "#> [0, 2, 4, 6, 8, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.arange(0, 1.1, 0.5)\n",
        "#> array([0. , 0.5, 1. ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.linspace(0, 100, 5)\n",
        "#> array([ 0., 25., 50., 75., 100.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[10] * 5\n",
        "#> [10, 10, 10, 10, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array([2, 3, 5, 7])\n",
        "\n",
        "x + 10 # \u52a0\u7b97\n",
        "#> array([12, 13, 15, 17])\n",
        "\n",
        "x * 10 # \u4e57\u7b97\n",
        "#> array([20, 30, 50, 70])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [2, 3]\n",
        "np.sin(x)\n",
        "#> array([0.90929743, 0.14112001])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([2,  3,   5,    7])\n",
        "y = np.array([1, 10, 100, 1000])\n",
        "x + y\n",
        "#> array([   3,   13,  105, 1007])\n",
        "\n",
        "x * y\n",
        "#> array([   2,   30,  500, 7000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.dot(x, y)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x @ y\n",
        "\n",
        "#> 7532"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([True, False])\n",
        "y = np.array([True, True])\n",
        "x & y\n",
        "#> array([ True, False])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "u = np.array([1, 2, 3])\n",
        "v = np.array([1, 2, 3])\n",
        "w = np.array([1, 2, 4])\n",
        "\n",
        "all(u == v) # \u5168\u4f53\u306e\u6bd4\u8f03\n",
        "#> True\n",
        "\n",
        "all(u == w) # \u5168\u4f53\u306e\u6bd4\u8f03\n",
        "#> False\n",
        "\n",
        "u == v      # \u8981\u7d20\u3054\u3068\u306e\u6bd4\u8f03\n",
        "#> array([ True,  True,  True])\n",
        "\n",
        "u == w      # \u8981\u7d20\u3054\u3068\u306e\u6bd4\u8f03\n",
        "#> array([ True,  True, False])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(u == w).sum()  # \u540c\u3058\u8981\u7d20\u306e\u6570\n",
        "#> 2\n",
        "\n",
        "(u == w).mean() # \u540c\u3058\u8981\u7d20\u306e\u5272\u5408\n",
        "#> [1] 0.6666667"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [1, \"two\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x[1]\n",
        "#> 'two'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = {'apple' : '\u308a\u3093\u3054',\n",
        "     'orange': '\u307f\u304b\u3093'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['grape'] = '\u3076\u3069\u3046'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['apple']\n",
        "# \u3042\u308b\u3044\u306f\n",
        "tmp = 'apple'\n",
        "x[tmp]\n",
        "\n",
        "#> '\u308a\u3093\u3054'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = ['foo', 'bar', 'baz']\n",
        "y = x\n",
        "y[1] = 'BAR' # y\u3092\u66f4\u65b0\u3059\u308b\uff0e\n",
        "y\n",
        "#> ['foo', 'BAR', 'baz']\n",
        "\n",
        "x            # x\u3082\u5909\u308f\u308b\uff0e\n",
        "#> ['foo', 'BAR', 'baz']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = ['foo', 'bar', 'baz']\n",
        "y = x.copy()             # \u300cy = x\u300d\u3068\u305b\u305a\u306b\uff0c\u30b3\u30d4\u30fc\u3059\u308b\uff0e\n",
        "x == y, x is y\n",
        "#> (True, False)         # x\u3068y\u306f\uff0c\u7b49\u4fa1\uff08\u5185\u5bb9\u306f\u540c\u3058\uff09\u3060\u304c\u540c\u4e00\u3067\u306f\u306a\u3044\uff0e\n",
        "\n",
        "y[1] = 'BAR'             # y\u3092\u66f4\u65b0\u3057\u3066\u3082\uff0c\n",
        "x\n",
        "#> ['foo', 'bar', 'baz'] # x\u306f\u5909\u5316\u3057\u306a\u3044\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame({\n",
        "    'name':    ['A', 'B', 'C', 'D'],\n",
        "    'english': [ 60,  90,  70,  90],\n",
        "    'math':    [ 70,  80,  90, 100],\n",
        "    'gender':  ['f', 'm', 'm', 'f']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame([\n",
        "    ['A', 60,  70, 'f'],\n",
        "    ['B', 90,  80, 'm'],\n",
        "    ['C', 70,  90, 'm'],\n",
        "    ['D', 90, 100, 'f']],\n",
        "    columns=['name', 'english',\n",
        "             'math', 'gender'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.head()\n",
        "# \u7d50\u679c\u306f\u5272\u611b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r, c = my_df.shape # \u884c\u6570\u3068\u5217\u6570\n",
        "r, c\n",
        "#> (4, 4)\n",
        "\n",
        "r # \u884c\u6570\uff08len(my_df)\u3082\u53ef\uff09\n",
        "#> 4\n",
        "\n",
        "c # \u5217\u6570\n",
        "#> 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "my_df2 = pd.DataFrame(\n",
        "    product([1, 2, 3],\n",
        "            [10, 100]),\n",
        "    columns=['X', 'Y'])\n",
        "my_df2\n",
        "#>    X    Y\n",
        "#> 0  1   10\n",
        "#> 1  1  100\n",
        "#> 2  2   10\n",
        "#> 3  2  100\n",
        "#> 4  3   10\n",
        "#> 5  3  100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2.columns\n",
        "#> Index(['X', 'Y'], dtype='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2.columns = ['P', 'Q']\n",
        "my_df2\n",
        "#>    P    Q\n",
        "#> 0  1   10\n",
        "#> 1  1  100\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(my_df.index)\n",
        "#> [0, 1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2.index = [\n",
        "    'a', 'b', 'c', 'd', 'e', 'f']\n",
        "my_df2\n",
        "#>    P    Q\n",
        "#> a  1   10\n",
        "#> b  1  100\n",
        "#> c  2   10\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df3 = pd.DataFrame({\n",
        "    'english': [ 60,  90,  70,  90],\n",
        "    'math':    [ 70,  80,  90, 100],\n",
        "    'gender':  ['f', 'm', 'm', 'f']},\n",
        "    index=     ['A', 'B', 'C', 'D'])\n",
        "my_df3\n",
        "#>    english  math gender\n",
        "#> A       60    70      f\n",
        "#> B       90    80      m\n",
        "#> C       70    90      m\n",
        "#> D       90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame({\n",
        "    'name'   : ['E'],\n",
        "    'english': [80],\n",
        "    'math'   : [80],\n",
        "    'gender' : ['m']})\n",
        "my_df2 = my_df.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2 = my_df.assign(id=[1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df3 = my_df.copy()       # \u30b3\u30d4\u30fc\n",
        "my_df3['id'] = [1, 2, 3, 4] # \u66f4\u65b0\n",
        "my_df3 # \u7d50\u679c\u306e\u78ba\u8a8d\uff08\u5272\u611b\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.iloc[0, 1]\n",
        "#> 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.iloc[:, 1]\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df['english']\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.english\n",
        "# \u3042\u308b\u3044\u306f\n",
        "tmp = 'english'\n",
        "x = my_df[tmp]\n",
        "\n",
        "x # \u7d50\u679c\u306e\u78ba\u8a8d\uff08\u5272\u611b\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df[['name', 'math']]\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.loc[:, ['name', 'math']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.take([0, 2], axis=1)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.iloc[:, [0, 2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.drop(\n",
        "    columns=['english', 'gender'])\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.drop(\n",
        "    columns=my_df.columns[[1, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.take([0, 2])\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.iloc[[0, 2], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.drop([1, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df[my_df['gender'] == 'm']\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.query('gender == \"m\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df[(my_df['english'] > 80) & (my_df['gender'] == \"m\")]\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = my_df.query('english > 80 and gender == \"m\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df[my_df['english'] == my_df['english'].max()]\n",
        "# \u3042\u308b\u3044\u306f\n",
        "tmp = my_df['english'].max()\n",
        "x = my_df.query('english == @tmp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2 = my_df.copy() # \u30b3\u30d4\u30fc\n",
        "my_df2.loc[my_df['gender'] == 'm', 'gender'] = 'M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2\n",
        "#>   name  english  math gender\n",
        "#> 0    A       60    70      f\n",
        "#> 1    B       90    80      M\n",
        "#> 2    C       70    90      M\n",
        "#> 3    D       90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.sort_values('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = my_df.sort_values('english',\n",
        "    ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = [2, 3, 5, 7, 11, 13, 17, 19, 23,\n",
        "     29, 31, 37]\n",
        "A = np.array(x).reshape(3, 4)\n",
        "A\n",
        "#> array([[ 2,  3,  5,  7],\n",
        "#>        [11, 13, 17, 19],\n",
        "#>        [23, 29, 31, 37]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A = my_df.iloc[:, [1, 2]].values\n",
        "A\n",
        "#> array([[ 60,  70],\n",
        "#>        [ 90,  80],\n",
        "#>        [ 70,  90],\n",
        "#>        [ 90, 100]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(A)\n",
        "#>     0    1\n",
        "#> 0  60   70\n",
        "#> 1  90   80\n",
        "#> 2  70   90\n",
        "#> 3  90  100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A.T\n",
        "#> array([[ 60,  90,  70,  90],\n",
        "#>        [ 70,  80,  90, 100]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A.T @ A\n",
        "#> array([[24700, 26700],\n",
        "#>        [26700, 29400]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame({\n",
        "    'day': [25, 26, 27],\n",
        "    'min': [20, 21, 15],\n",
        "    'max': [24, 27, 21]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_longer = my_df.melt(id_vars='day')\n",
        "my_longer\n",
        "#>    day variable  value\n",
        "#> 0   25      min     20\n",
        "#> 1   26      min     21\n",
        "#> 2   27      min     15\n",
        "#> 3   25      max     24\n",
        "#> 4   26      max     27\n",
        "#> 5   27      max     21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_wider = my_longer.pivot(\n",
        "    index='day',\n",
        "    columns='variable',\n",
        "    values='value')\n",
        "my_wider\n",
        "#> variable  max  min\n",
        "#> day\n",
        "#> 25         24   20\n",
        "#> 26         27   21\n",
        "#> 27         21   15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_wider.plot(\n",
        "    style='o-',\n",
        "    xticks=my_wider.index, # x\u8ef8\u76ee\u76db\u308a\n",
        "    ylabel='temperature')  # y\u8ef8\u30e9\u30d9\u30eb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "A = np.array([3,   4,  5])\n",
        "B = np.array([3,   4, 29])\n",
        "C = np.array([9, -18,  8])\n",
        "\n",
        "distance.euclidean(A, B)\n",
        "#> 24.0\n",
        "\n",
        "distance.euclidean(A, C)\n",
        "#> 23.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distance.cityblock(A, B)\n",
        "#> 24\n",
        "\n",
        "distance.cityblock(A, C)\n",
        "#> 31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 - distance.cosine(A, B)\n",
        "#> 0.8169678632647616\n",
        "\n",
        "1 - distance.cosine(A, C)\n",
        "#> -0.032651157422416865"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1 - distance.correlation(A, B)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "pearsonr(A, B)[0]\n",
        "#> 0.8824975032927698\n",
        "\n",
        "1 - distance.correlation(A, C)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "pearsonr(A, C)[0]\n",
        "#> -0.032662766723200676"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u5c0f\u6570\u70b9\u4ee5\u4e0b\u306f3\u6841\u8868\u793a\n",
        "np.set_printoptions(precision=3)\n",
        "import pandas as pd\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    'x': [3,  3,   9],\n",
        "    'y': [4,  4, -18],\n",
        "    'z': [5, 29,   8]},\n",
        "    index=['A', 'B', 'C'])\n",
        "\n",
        "# \u30e6\u30fc\u30af\u30ea\u30c3\u30c9\u8ddd\u96e2\n",
        "distance.cdist(my_df, my_df,\n",
        "               metric='euclidean')\n",
        "#> array([[ 0., 24., 23.],\n",
        "#>        [24.,  0., 31.],\n",
        "#>        [23., 31.,  0.]])\n",
        "\n",
        "# \u30de\u30f3\u30cf\u30c3\u30bf\u30f3\u8ddd\u96e2\n",
        "distance.cdist(my_df, my_df,\n",
        "               metric='cityblock')\n",
        "#> array([[ 0., 24., 31.],\n",
        "#>        [24.,  0., 49.],\n",
        "#>        [31., 49.,  0.]])\n",
        "\n",
        "# \u30b3\u30b5\u30a4\u30f3\u985e\u4f3c\u5ea6\n",
        "1 - distance.cdist(my_df, my_df,\n",
        "    metric='cosine')\n",
        "#> array([[ 1.   ,  0.817, -0.033],\n",
        "#>        [ 0.817,  1.   ,  0.293],\n",
        "#>        [-0.033,  0.293,  1.   ]])\n",
        "\n",
        "# \u76f8\u95a2\u4fc2\u6570\n",
        "1 - distance.cdist(my_df, my_df,\n",
        "    metric='correlation')\n",
        "#> array([[ 1.   ,  0.882, -0.033],\n",
        "#>        [ 0.882,  1.   ,  0.441],\n",
        "#>        [-0.033,  0.441,  1.   ]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "numpy.array([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.array([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "array([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import *\n",
        "array([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1(x):\n",
        "    tmp = np.random.random(x)\n",
        "    return np.mean(tmp)\n",
        "\n",
        "f1(10)                # \u52d5\u4f5c\u78ba\u8a8d\n",
        "#> 0.5427033207230424 # \u7d50\u679c\u306e\u4f8b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[f1(10) for i in range(3)]\n",
        "#> [0.4864425069985622,\n",
        "#>  0.4290935578857099,\n",
        "#>  0.535206509631883]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[f1(10)] * 3\n",
        "#> [0.43725641184595576,\n",
        "#>  0.43725641184595576,\n",
        "#>  0.43725641184595576]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v = [5, 10, 100]\n",
        "[f1(x) for x in v] # \u65b9\u6cd51\n",
        "#> [0.454, 0.419, 0.552]\n",
        "\n",
        "# \u3042\u308b\u3044\u306f\n",
        "\n",
        "v = pd.Series([5, 10, 100])\n",
        "v.apply(f1)        # \u65b9\u6cd52\n",
        "#> 0    0.394206\n",
        "#> 1    0.503949\n",
        "#> 2    0.532698\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.Series([10] * 3).apply(f1)\n",
        "# \u7d50\u679c\u306f\u5272\u611b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f2(n):\n",
        "    tmp = np.random.random(n)\n",
        "    return pd.Series([\n",
        "        n,\n",
        "        tmp.mean(),\n",
        "        tmp.std(ddof=1)],\n",
        "        index=['x', 'p', 'q'])\n",
        "\n",
        "f2(10) # \u52d5\u4f5c\u78ba\u8a8d\n",
        "#> x    10.000000\n",
        "#> p     0.405898 \uff08\u5e73\u5747\u306e\u4f8b\uff09\n",
        "#> q     0.317374 \uff08\u6a19\u6e96\u504f\u5dee\u306e\u4f8b\uff09\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v = pd.Series([5, 10, 100])\n",
        "v.apply(f2)\n",
        "#>        x         p         q\n",
        "#> 0    5.0  0.507798  0.207970\n",
        "#> 1   10.0  0.687198  0.264427\n",
        "#> 2  100.0  0.487872  0.280743"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f3(x, y):\n",
        "    tmp = np.random.random(x) * y\n",
        "    return pd.Series([\n",
        "        x,\n",
        "        y,\n",
        "        tmp.mean(),\n",
        "        tmp.std(ddof=1)],\n",
        "        index=['x', 'y', 'p', 'q'])\n",
        "\n",
        "f3(10, 6) # \u52d5\u4f5c\u78ba\u8a8d\n",
        "#> x    10.000000\n",
        "#> y     6.000000\n",
        "#> p     2.136413 \uff08\u5e73\u5747\u306e\u4f8b\uff09\n",
        "#> q     1.798755 \uff08\u6a19\u6e96\u504f\u5dee\u306e\u4f8b\uff09\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame({\n",
        "    'x': [5, 10, 100,  5, 10, 100],\n",
        "    'y': [6,  6,   6, 12, 12,  12]})\n",
        "\n",
        "my_df.apply(\n",
        "  lambda row: f3(row['x'], row['y']),\n",
        "  axis=1)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_df.apply(lambda row:\n",
        "            f3(*row), axis=1)\n",
        "\n",
        "#>        x     y    p    q\n",
        "#> 0   5.00  6.00 3.37 1.96\n",
        "#> 1  10.00  6.00 1.92 0.95\n",
        "#> 2 100.00  6.00 2.90 1.73\n",
        "#> 3   5.00 12.00 6.82 3.00\n",
        "#> 4  10.00 12.00 7.05 2.42\n",
        "#> 5 100.00 12.00 5.90 3.54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize() # \u6e96\u5099\n",
        "\n",
        "v = pd.Series([5, 10, 100])\n",
        "v.parallel_apply(f1)\n",
        "# \u7d50\u679c\u306f\u5272\u611b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 123\n",
        "type(x)\n",
        "#> int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%whos\n",
        "#> Variable   Type      Data/Info\n",
        "#> ------------------------------\n",
        "#> x          int       123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "?math.log\n",
        "# \u3042\u308b\u3044\u306f\n",
        "help(math.log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "v = [1, np.nan, 3]\n",
        "v\n",
        "#> [1, nan, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.isnan(v[1])\n",
        "#> True\n",
        "\n",
        "v[1] == np.nan # \u8aa4\u308a\n",
        "#> False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x = [165, 170, 175, 180, 185]\n",
        "np.mean(x) # \u30ea\u30b9\u30c8\u306e\u5834\u5408\n",
        "#> 175.0\n",
        "\n",
        "x = np.array( # \u30a2\u30ec\u30a4\n",
        "    [165, 170, 175, 180, 185])\n",
        "x.mean() # np.mean(x)\u3082\u53ef\n",
        "#> 175.0\n",
        "\n",
        "x = pd.Series( # \u30b7\u30ea\u30fc\u30ba\n",
        "    [165, 170, 175, 180, 185])\n",
        "x.mean() # np.mean(x)\u3082\u53ef\n",
        "#> 175.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = len(x) # \u30b5\u30f3\u30d7\u30eb\u30b5\u30a4\u30ba\n",
        "sum(x) / n\n",
        "#> 175.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = [173, 174, 175, 176, 177]\n",
        "np.mean(y)\n",
        "#> 175.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.var(x, ddof=1) # x\u306e\u5206\u6563\n",
        "#> 62.5\n",
        "\n",
        "np.var(y, ddof=1) # y\u306e\u5206\u6563\n",
        "#> 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum((x - np.mean(x))**2) / (n - 1)\n",
        "#> 62.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.std(x, ddof=1) # x\u306e\u6a19\u6e96\u504f\u5dee\n",
        "#> 7.905694150420948\n",
        "\n",
        "np.std(y, ddof=1) # y\u306e\u6a19\u6e96\u504f\u5dee\n",
        "#> 1.5811388300841898"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.var(x, ddof=1)**0.5 # x\u306e\u6a19\u6e96\u504f\u5dee\n",
        "#> 7.905694150420948"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = pd.Series(x)\n",
        "s.describe()\n",
        "#> count      5.000000 \uff08\u30c7\u30fc\u30bf\u6570\uff09\n",
        "#> mean     175.000000 \uff08\u5e73\u5747\uff09\n",
        "#> std        7.905694 \uff08\u6a19\u6e96\u504f\u5dee\uff09\n",
        "#> min      165.000000 \uff08\u6700\u5c0f\u5024\uff09\n",
        "#> 25%      170.000000 \uff08\u7b2c1\u56db\u5206\u4f4d\u6570\uff09\n",
        "#> 50%      175.000000 \uff08\u4e2d\u592e\u5024\uff09\n",
        "#> 75%      180.000000 \uff08\u7b2c3\u56db\u5206\u4f4d\u6570\uff09\n",
        "#> max      185.000000 \uff08\u6700\u5927\u5024\uff09\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s.describe()\u3067\u8a08\u7b97\u6e08\u307f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [165, 170, 175, 180, 185]\n",
        "\n",
        "np.var(x, ddof=1) # \u4e0d\u504f\u5206\u6563\n",
        "#> 62.5\n",
        "\n",
        "np.var(x, ddof=0) # \u6a19\u672c\u5206\u6563\n",
        "#> 50.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.std(x, ddof=1) # \u221a\u4e0d\u504f\u5206\u6563\n",
        "#> 7.905694150420949\n",
        "\n",
        "np.std(x, ddof=0) # \u221a\u6a19\u672c\u5206\u6563\n",
        "#> 7.0710678118654755"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.std(x, ddof=1) / len(x)**0.5\n",
        "#> 3.5355339059327373"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    'name':    ['A', 'B', 'C', 'D'],\n",
        "    'english': [ 60,  90,  70,  90],\n",
        "    'math':    [ 70,  80,  90, 100],\n",
        "    'gender':  ['f', 'm', 'm', 'f']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df['english'].var(ddof=1)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "np.var(my_df['english'], ddof=1)\n",
        "\n",
        "#> 225.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.var()\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_df.apply('var')\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_df.iloc[:, [1, 2]].apply(\n",
        "    lambda x: np.var(x, ddof=1))\n",
        "\n",
        "#> english    225.000000\n",
        "#> math       166.666667\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.describe()\n",
        "#>        english        math\n",
        "#> count      4.0    4.000000\n",
        "#> mean      77.5   85.000000\n",
        "#> std       15.0   12.909944\n",
        "#> min       60.0   70.000000\n",
        "#> 25%       67.5   77.500000\n",
        "#> 50%       80.0   85.000000\n",
        "#> 75%       90.0   92.500000\n",
        "#> max       90.0  100.000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "Counter(my_df.gender)\n",
        "#> Counter({'f': 2, 'm': 2})\n",
        "\n",
        "# \u3042\u308b\u3044\u306f\n",
        "\n",
        "my_df.groupby('gender').apply(len)\n",
        "#> gender\n",
        "#> f    2\n",
        "#> m    2\n",
        "#> dtype: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2 = my_df.assign(\n",
        "    excel=my_df.math >= 80)\n",
        "pd.crosstab(my_df2.gender,\n",
        "            my_df2.excel)\n",
        "#> excel   False  True\n",
        "#> gender\n",
        "#> f           1      1\n",
        "#> m           0      2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.groupby('gender').mean()\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_df.groupby('gender').agg('mean')\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_df.groupby('gender').agg(np.mean)\n",
        "\n",
        "#>         english  math\n",
        "#> gender\n",
        "#> f          75.0  85.0\n",
        "#> m          80.0  85.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "iris = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "iris.head()\n",
        "#>    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
        "#> 0           5.1          3.5           1.4          0.2  setosa\n",
        "#> 1           4.9          3.0           1.4          0.2  setosa\n",
        "#> 2           4.7          3.2           1.3          0.2  setosa\n",
        "#> 3           4.6          3.1           1.5          0.2  setosa\n",
        "#> 4           5.0          3.6           1.4          0.2  setosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.hist('Sepal.Length')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame(\n",
        "    {'x': [10, 20, 30]})\n",
        "my_df.hist('x', bins=2) # \u968e\u7d1a\u6570\u306f2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = iris['Sepal.Length']\n",
        "tmp = np.linspace(min(x), max(x), 10)\n",
        "iris.hist('Sepal.Length',\n",
        "          bins=tmp.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.plot('Sepal.Length',\n",
        "          'Sepal.Width',\n",
        "          kind='scatter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris.boxplot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.float_format = (\n",
        "    '{:.2f}'.format)\n",
        "my_df = (iris.describe().transpose()\n",
        "    [['mean', 'std']])\n",
        "my_df['se'] = (my_df['std'] /\n",
        "               len(iris)**0.5)\n",
        "my_df\n",
        "#>               mean  std   se\n",
        "#> Sepal.Length  5.84 0.83 0.07\n",
        "#> Sepal.Width   3.06 0.44 0.04\n",
        "#> Petal.Length  3.76 1.77 0.14\n",
        "#> Petal.Width   1.20 0.76 0.06"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.plot(y='mean', kind='bar', yerr='se', capsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_group = iris.groupby('Species')                    # \u54c1\u7a2e\u3054\u3068\u306b\uff0c\n",
        "my_df = my_group.agg('mean')                          # \u5404\u5909\u6570\u306e\uff0c\u5e73\u5747\u3068\n",
        "my_se = my_group.agg(lambda x: x.std() / len(x)**0.5) # \u6a19\u6e96\u8aa4\u5dee\u3092\u6c42\u3081\u308b\uff0e\n",
        "my_se\n",
        "#>             Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
        "#> Species\n",
        "#> setosa              0.05         0.05          0.02         0.01\n",
        "#> versicolor          0.07         0.04          0.07         0.03\n",
        "#> virginica           0.09         0.05          0.08         0.04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_group.agg('mean').plot(kind='bar', yerr=my_se, capsize=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.graphics.mosaicplot \\\n",
        "    import mosaic\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    'Species': iris.Species,\n",
        "    'w_Sepal': iris['Sepal.Width'] > 3})\n",
        "\n",
        "my_table = pd.crosstab( # \u5206\u5272\u8868\n",
        "    my_df['Species'],\n",
        "    my_df['w_Sepal'])\n",
        "my_table\n",
        "#> w_Sepal     False  True\n",
        "#> Species\n",
        "#> setosa          8     42\n",
        "#> versicolor     42      8\n",
        "#> virginica      33     17\n",
        "\n",
        "mosaic(my_df,\n",
        "       index=['Species', 'w_Sepal'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_table.columns = [str(x) for x in my_table.columns]\n",
        "my_table.index   = [str(x) for x in my_table.index]\n",
        "mosaic(my_df, index=['Species', 'w_Sepal'], labelizer=lambda k: my_table.loc[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-2, 2, 100)\n",
        "y = x**3 - x\n",
        "plt.plot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "rng = np.random.default_rng()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.choice(\n",
        "    a=range(1, 7), # 1\u304b\u30896\n",
        "    size=10000,    # \u4e71\u6570\u306e\u6570\n",
        "    replace=True)  # \u91cd\u8907\u3042\u308a\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = np.random.randint(\n",
        "# \u3042\u308b\u3044\u306f\n",
        "#x = rng.integers(\n",
        "    low=1,      # \u6700\u5c0f\n",
        "    high=7,     # \u6700\u5927+1\n",
        "    size=10000) # \u4e71\u6570\u306e\u6570\n",
        "\n",
        "plt.hist(x, bins=6) # \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.random.random(size=1000)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = rng.random(size=10000)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "x = np.random.uniform(\n",
        "    low=0,     # \u6700\u5c0f\n",
        "    high=1,    # \u6700\u5927\n",
        "    size=1000) # \u4e71\u6570\u306e\u6570\n",
        "plt.hist(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = np.random.uniform(\n",
        "    low=1,     # \u6700\u5c0f\n",
        "    high=7,    # \u6700\u5927 + 1\n",
        "    size=1000) # \u4e71\u6570\u306e\u6570\n",
        "x = [int(k) for k in tmp]\n",
        "plt.hist(x, bins=6) # \u7d50\u679c\u306f\u5272\u611b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 100\n",
        "p = 0.5\n",
        "r = 10000\n",
        "x = np.random.binomial(\n",
        "# \u3042\u308b\u3044\u306f\n",
        "#x = rng.binomial(\n",
        "    n=n,    # \u8a66\u884c\u56de\u6570\n",
        "    p=p,    # \u78ba\u7387\n",
        "    size=r) # \u4e71\u6570\u306e\u6570\n",
        "plt.hist(x, bins=max(x) - min(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = 10000\n",
        "x = np.random.normal(\n",
        "# \u3042\u308b\u3044\u306f\n",
        "#x = rng.normal(\n",
        "    loc=50,  # \u5e73\u5747\n",
        "    scale=5, # \u6a19\u6e96\u504f\u5dee\n",
        "    size=r)  # \u4e71\u6570\u306e\u6570\n",
        "plt.hist(x, bins=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def f(k):\n",
        "    n = 10000\n",
        "    tmp = [g(np.random.normal(size=k, scale=3)) for _ in range(n)]\n",
        "    return pd.Series([k,\n",
        "                      np.mean(tmp),                  # \u5e73\u5747\n",
        "                      np.std(tmp, ddof=1) / n**0.5], # \u6a19\u6e96\u8aa4\u5dee\n",
        "                     index=['k', 'mean', 'se'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def g(x):\n",
        "    return np.var(x, ddof=1)\n",
        "pd.Series([10, 20, 30]).apply(f)\n",
        "#>       k      mean        se\n",
        "#> 0  10.0  9.025140  0.042690\n",
        "#> 1  20.0  9.022280  0.029525\n",
        "#> 2  30.0  8.983166  0.023584"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def g(x):\n",
        "    return np.std(x, ddof=1)\n",
        "pd.Series([10, 20, 30]).apply(f)\n",
        "#>       k      mean        se\n",
        "#> 0  10.0  2.923114  0.006983\n",
        "#> 1  20.0  2.961450  0.004811\n",
        "#> 2  30.0  2.968328  0.003977"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import gamma\n",
        "\n",
        "def g(x):\n",
        "    n = len(x)\n",
        "    return (np.std(x, ddof=1) *\n",
        "            (np.sqrt((n - 1) / 2) *\n",
        "             gamma((n - 1) / 2) /\n",
        "             gamma(n / 2)))\n",
        "pd.Series([10, 20, 30]).apply(f)\n",
        "#>       k      mean        se\n",
        "#> 0  10.0  3.005788  0.007121\n",
        "#> 1  20.0  3.001857  0.004894\n",
        "#> 2  30.0  2.995965  0.003925"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.proportion import binom_test, proportion_confint\n",
        "\n",
        "binom_test(count=2,                 # \u5f53\u305f\u3063\u305f\u56de\u6570\n",
        "           nobs=15,                 # \u304f\u3058\u3092\u5f15\u3044\u305f\u56de\u6570\n",
        "           prop=4 / 10,             # \u5f53\u305f\u308b\u78ba\u7387\uff08\u4eee\u8aac\uff09\n",
        "           alternative='two-sided') # \u4e21\u5074\u691c\u5b9a\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\n",
        "                                    # \u5de6\u7247\u5074\u691c\u5b9a\u306a\u3089'smaller'\n",
        "                                    # \u53f3\u7247\u5074\u691c\u5b9a\u306a\u3089'larger'\n",
        "#> 0.03646166155263999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "t = 4 / 10                        # \u5f53\u305f\u308b\u78ba\u7387\n",
        "n = 15                            # \u304f\u3058\u3092\u5f15\u3044\u305f\u56de\u6570\n",
        "x = np.array(range(0, n + 1))     # \u5f53\u305f\u3063\u305f\u56de\u6570\n",
        "my_pr  = stats.binom.pmf(x, n, t) # x\u56de\u5f53\u305f\u308b\u78ba\u7387\n",
        "my_pr2 = stats.binom.pmf(2, n, t) # 2\u56de\u5f53\u305f\u308b\u78ba\u7387\n",
        "\n",
        "my_data = pd.DataFrame({'x': x, 'y1': my_pr, 'y2': my_pr})\n",
        "my_data.loc[my_pr >  my_pr2, 'y1'] = np.nan # \u5f53\u305f\u308b\u78ba\u7387\u304c\uff0c2\u56de\u5f53\u305f\u308b\u78ba\u7387\u8d85\u904e\n",
        "my_data.loc[my_pr <= my_pr2, 'y2'] = np.nan # \u5f53\u305f\u308b\u78ba\u7387\u304c\uff0c2\u56de\u5f53\u305f\u308b\u78ba\u7387\u4ee5\u4e0b\n",
        "ax = my_data.plot(x='x', style='o', ylabel='probability',\n",
        "                  legend=False)         # \u51e1\u4f8b\u3092\u8868\u793a\u3057\u306a\u3044\uff0e\n",
        "ax.hlines(y=my_pr2, xmin=0, xmax=15)    # \u6c34\u5e73\u7dda\n",
        "ax.vlines(x=x,      ymin=0, ymax=my_pr) # \u5782\u76f4\u7dda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = 0.05\n",
        "proportion_confint(\n",
        "    count=2, # \u5f53\u305f\u3063\u305f\u56de\u6570\n",
        "    nobs=15, # \u304f\u3058\u3092\u5f15\u3044\u305f\u56de\u6570\n",
        "    alpha=a, # \u6709\u610f\u6c34\u6e96\uff08\u7701\u7565\u53ef\uff09\n",
        "    method='binom_test')\n",
        "#> (0.024225732468536626,\n",
        "#>  0.3967139842509865)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = 0.05 # \u6709\u610f\u6c34\u6e96\n",
        "tmp = np.linspace(0, 1, 100)\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    't': tmp,                                                  # \u5f53\u305f\u308b\u78ba\u7387\n",
        "    'q': a,                                                    # \u6c34\u5e73\u7dda\n",
        "    'p': [binom_test(count=2, nobs=15, prop=t) for t in tmp]}) # p\u5024\n",
        "\n",
        "my_df.plot(x='t', legend=None, xlabel=r'$\\theta$', ylabel=r'p-value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.weightstats import CompareMeans, DescrStatsW\n",
        "\n",
        "X = [32.1, 26.2, 27.5, 31.8, 32.1, 31.2, 30.1, 32.4, 32.3, 29.9,\n",
        "     29.6, 26.6, 31.2, 30.9, 29.3]\n",
        "Y = [35.4, 34.6, 31.1, 32.4, 33.3, 34.7, 35.3, 34.3, 32.1, 28.3,\n",
        "     33.3, 30.5, 32.6, 33.3, 32.2]\n",
        "\n",
        "a = 0.05          # \u6709\u610f\u6c34\u6e96\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09 = 1 - \u4fe1\u983c\u4fc2\u6570\n",
        "alt = 'two-sided' # \u4e21\u5074\u691c\u5b9a\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\n",
        "                  # \u5de6\u7247\u5074\u691c\u5b9a\u306a\u3089'smaller'\n",
        "                  # \u53f3\u7247\u5074\u691c\u5b9a\u306a\u3089'larger'\n",
        "\n",
        "d = DescrStatsW(np.array(X) - np.array(Y)) # \u5bfe\u6a19\u672c\u306e\u5834\u5408\n",
        "d.ttest_mean(alternative=alt)[1]           # p\u5024\n",
        "#> 0.0006415571512322235\n",
        "\n",
        "d.tconfint_mean(alpha=a, alternative=alt) # \u4fe1\u983c\u533a\u9593\n",
        "#> (-3.9955246743198867, -1.3644753256801117)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = CompareMeans(DescrStatsW(X), DescrStatsW(Y)) # \u5bfe\u6a19\u672c\u3067\u306a\u3044\u5834\u5408\n",
        "\n",
        "ve = 'pooled' # \u7b49\u5206\u6563\u3092\u4eee\u5b9a\u3059\u308b\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\uff0e\u4eee\u5b9a\u3057\u306a\u3044\u306a\u3089'unequal'\uff0e\n",
        "c.ttest_ind(alternative=alt, usevar=ve)[1] # p\u5024\n",
        "#> 0.000978530937238609\n",
        "\n",
        "c.tconfint_diff(alpha=a, alternative=alt, usevar=ve) # \u4fe1\u983c\u533a\u9593\n",
        "#> (-4.170905570517185, -1.1890944294828283)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/smoker.csv')\n",
        "my_data = pd.read_csv(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.head()\n",
        "#>   alive smoker\n",
        "#> 0   Yes     No\n",
        "#> 1   Yes     No\n",
        "#> 2   Yes     No\n",
        "#> 3   Yes     No\n",
        "#> 4   Yes     No"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_table = pd.crosstab(\n",
        "    my_data['alive'],\n",
        "    my_data['smoker'])\n",
        "my_table\n",
        "#> smoker   No  Yes\n",
        "#> alive\n",
        "#> No      117   54\n",
        "#> Yes     950  348"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "chi2_contingency(my_table, correction=False)[1]\n",
        "#> 0.18860725715300422"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = [0] * 13 + [1] * 2 # \u624b\u98061\n",
        "X\n",
        "#> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
        "\n",
        "tmp = np.random.choice(X, 15, replace=True) # \u624b\u98062\n",
        "tmp\n",
        "#> array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
        "\n",
        "sum(tmp) # \u624b\u98063\n",
        "#> 2\n",
        "\n",
        "n = 10**5\n",
        "result = [sum(np.random.choice(X, len(X), replace=True)) for _ in range(n)] # \u624b\u98064"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(result, bins=range(0, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.quantile(result, [0.025, 0.975])\n",
        "#> array([0., 5.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/taroyabuki/fromzero/master/data/exam.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "my_df = pd.read_csv('exam.csv')\n",
        "my_df\n",
        "#>   name  english  math gender\n",
        "#> 0    A       60    70      f\n",
        "#> 1    B       90    80      m\n",
        "#> 2    C       70    90      m\n",
        "#> 3    D       90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/exam.csv')\n",
        "my_df = pd.read_csv(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2 = pd.read_csv('exam.csv',\n",
        "    index_col='name')\n",
        "my_df2\n",
        "#>       english  math gender\n",
        "#> name\n",
        "#> A          60    70      f\n",
        "#> B          90    80      m\n",
        "#> C          70    90      m\n",
        "#> D          90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.to_csv('exam2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2.to_csv('exam3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.read_csv('exam.csv',\n",
        "    encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.to_csv('exam2.csv', index=False, encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_url = 'https://taroyabuki.github.io/fromzero/exam.html'\n",
        "my_tables = pd.read_html(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_tables\n",
        "#> [   Unnamed: 0 name  english ...\n",
        "#>  0         NaN    A       60 ...\n",
        "#>  1         NaN    B       90 ...\n",
        "#>  2         NaN    C       70 ...\n",
        "#>  3         NaN    D       90 ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_tables[0]\n",
        "#>    Unnamed: 0 name  english ...\n",
        "#> 0         NaN    A       60 ...\n",
        "#> 1         NaN    B       90 ...\n",
        "#> 2         NaN    C       70 ...\n",
        "#> 3         NaN    D       90 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1\u5217\u76ee\u4ee5\u964d\u3092\u53d6\u308a\u51fa\u3059\uff0e\n",
        "my_data = my_tables[0].iloc[:, 1:]\n",
        "my_data\n",
        "#>   name  english  math gender\n",
        "#> 0    A       60    70      f\n",
        "#> 1    B       90    80      m\n",
        "#> 2    C       70    90      m\n",
        "#> 3    D       90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/exam.json')\n",
        "my_data = pd.read_json(my_url)\n",
        "#my_data = pd.read_json('exam.json') # \uff08\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u3046\u5834\u5408\uff09\n",
        "my_data\n",
        "#>   name  english  math gender\n",
        "#> 0    A       60    70      f\n",
        "#> 1    B       90    80      m\n",
        "#> 2    C       70    90      m\n",
        "#> 3    D       90   100      f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from urllib.request import urlopen\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/exam.xml')\n",
        "with urlopen(my_url) as f:\n",
        "    my_tree = ET.parse(f)       # XML\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n",
        "\n",
        "#my_tree = ET.parse('exam.xml') # \uff08\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u3046\u5834\u5408\uff09\n",
        "my_ns = '{https://www.example.net/ns/1.0}' # \u540d\u524d\u7a7a\u9593"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_records = my_tree.findall(f'.//{my_ns}record')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(record):\n",
        "    my_dic1 = record.attrib # \u5c5e\u6027\u3092\u53d6\u308a\u51fa\u3059\uff0e\n",
        "    # \u5b50\u8981\u7d20\u306e\u540d\u524d\u3068\u5185\u5bb9\u306e\u30da\u30a2\u3092\u8f9e\u66f8\u306b\u3059\u308b\uff0e\n",
        "    my_dic2 = {child.tag.replace(my_ns, ''): child.text for child in list(record)}\n",
        "    return {**my_dic1, **my_dic2} # \u8f9e\u66f8\u3092\u7d50\u5408\u3059\u308b\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data = pd.DataFrame([f(record) for record in my_records])\n",
        "my_data['english'] = pd.to_numeric(my_data['english'])\n",
        "my_data['math']    = pd.to_numeric(my_data['math'])\n",
        "my_data\n",
        "#>    english  math gender name\n",
        "#> 0       60    70      f    A\n",
        "#> 1       90    80      m    B\n",
        "#> 2       70    90      m    C\n",
        "#> 3       90   100      f    D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "x1 = [1, 2, 3]\n",
        "\n",
        "z1 = ((x1 - np.mean(x1)) /\n",
        "      np.std(x1, ddof=1))\n",
        "# \u3042\u308b\u3044\u306f\n",
        "z1 = zscore(x1, ddof=1)\n",
        "\n",
        "z1\n",
        "#> array([-1.,  0.,  1.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z1.mean(), np.std(z1, ddof=1)\n",
        "#> (0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z1 * np.std(x1, ddof=1) + np.mean(x1)\n",
        "#> array([1., 2., 3.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x2 = [1, 3, 5]\n",
        "z2 = ((x2 - np.mean(x1)) /\n",
        "      np.std(x1, ddof=1))\n",
        "z2.mean(), np.std(z2, ddof=1)\n",
        "#> (1.0, 2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import (\n",
        "    OneHotEncoder)\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    'id':    [ 1 ,  2 ,  3 ],\n",
        "    'class': ['A', 'B', 'C']})\n",
        "\n",
        "my_enc = OneHotEncoder()\n",
        "tmp = my_enc.fit_transform(\n",
        "    my_df[['class']]).toarray()\n",
        "my_names = my_enc.get_feature_names() \\\n",
        "if hasattr(my_enc, 'get_feature_names') \\\n",
        "else my_enc.get_feature_names_out()\n",
        "pd.DataFrame(tmp, columns=my_names)\n",
        "#>    x0_A  x0_B  x0_C\n",
        "#> 0   1.0   0.0   0.0\n",
        "#> 1   0.0   1.0   0.0\n",
        "#> 2   0.0   0.0   1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df2 = pd.DataFrame({\n",
        "    'id':    [ 4 ,  5,   6 ],\n",
        "    'class': ['B', 'C', 'B']})\n",
        "tmp = my_enc.transform(\n",
        "    my_df2[['class']]).toarray()\n",
        "pd.DataFrame(tmp, columns=my_names)\n",
        "#>    x0_A  x0_B  x0_C\n",
        "#> 0   0.0   1.0   0.0\n",
        "#> 1   0.0   0.0   1.0\n",
        "#> 2   0.0   1.0   0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_enc = OneHotEncoder(drop='first')\n",
        "\n",
        "tmp = my_enc.fit_transform(\n",
        "    my_df[['class']]).toarray()\n",
        "my_names = my_enc.get_feature_names() \\\n",
        "if hasattr(my_enc, 'get_feature_names') \\\n",
        "else my_enc.get_feature_names_out()\n",
        "pd.DataFrame(tmp, columns=my_names)\n",
        "#>    x0_B  x0_C\n",
        "#> 0   0.0   0.0\n",
        "#> 1   1.0   0.0\n",
        "#> 2   0.0   1.0\n",
        "\n",
        "tmp = my_enc.transform(\n",
        "    my_df2[['class']]).toarray()\n",
        "pd.DataFrame(tmp, columns=my_names)\n",
        "#>    x0_B  x0_C\n",
        "#> 0   1.0   0.0\n",
        "#> 1   0.0   1.0\n",
        "#> 2   1.0   0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "iris = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "iris.head()\n",
        "#>    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
        "#> 0           5.1          3.5           1.4          0.2  setosa\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')\n",
        "iris.head()\n",
        "#>    sepal_length  sepal_width  petal_length  petal_width species\n",
        "#> 0           5.1          3.5           1.4          0.2  setosa\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "tmp = load_iris()\n",
        "iris = pd.DataFrame(tmp.data, columns=tmp.feature_names)\n",
        "iris['target'] = tmp.target_names[tmp.target]\n",
        "iris.head()\n",
        "#>    sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
        "#> 0                5.1               3.5  ...               0.2  setosa\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.shape\n",
        "#> (50, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.head()\n",
        "#>    speed  dist\n",
        "#> 0      4     2\n",
        "#> 1      4    10\n",
        "#> 2      7     4\n",
        "#> 3      7    22\n",
        "#> 4      8    16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.describe()\n",
        "#>            speed        dist\n",
        "#> count  50.000000   50.000000\n",
        "#> mean   15.400000   42.980000\n",
        "#> std     5.287644   25.769377\n",
        "#> min     4.000000    2.000000\n",
        "#> 25%    12.000000   26.000000\n",
        "#> 50%    15.000000   36.000000\n",
        "#> 75%    19.000000   56.000000\n",
        "#> max    25.000000  120.000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.plot(x='speed', style='o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "ax = sns.regplot(x='speed', y='dist', data=my_data)\n",
        "ax.vlines(x=21.5, ymin=-5, ymax=67,   linestyles='dotted')\n",
        "ax.hlines(y=67,   xmin=4,  xmax=21.5, linestyles='dotted')\n",
        "ax.set_xlim(4, 25)\n",
        "ax.set_ylim(-5, 125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u30e2\u30c7\u30eb\u306e\u6307\u5b9a\n",
        "from sklearn.linear_model import LinearRegression\n",
        "my_model = LinearRegression()\n",
        "\n",
        "# \u8a13\u7df4\uff08\u30e2\u30c7\u30eb\u3092\u30c7\u30fc\u30bf\u306b\u30d5\u30a3\u30c3\u30c8\u3055\u305b\u308b\uff0e\uff09\n",
        "my_model.fit(X, y)\n",
        "\n",
        "# \u307e\u3068\u3081\u3066\u5b9f\u884c\u3057\u3066\u3082\u3088\u3044\uff0e\n",
        "# my_model = LinearRegression().fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.intercept_, my_model.coef_\n",
        "#> (-17.579094890510973,\n",
        "#>  array([3.93240876]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = [[21.5]]\n",
        "my_model.predict(tmp)\n",
        "#> array([66.96769343])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tmp = pd.DataFrame({'speed': np.linspace(min(my_data.speed),\n",
        "                                         max(my_data.speed),\n",
        "                                         100)})\n",
        "tmp['model'] = my_model.predict(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.concat([my_data, tmp]).plot(\n",
        "    x='speed', style=['o', '-'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "my_model = LinearRegression()\n",
        "my_model.fit(X, y)\n",
        "y_ = my_model.predict(X)\n",
        "my_data['y_'] = y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.float_format = (\n",
        "    '{:.2f}'.format)\n",
        "my_data['residual'] = y - y_\n",
        "my_data.head()\n",
        "#>    speed  dist    y_  residual\n",
        "#> 0      4     2 -1.85      3.85\n",
        "#> 1      4    10 -1.85     11.85\n",
        "#> 2      7     4  9.95     -5.95\n",
        "#> 3      7    22  9.95     12.05\n",
        "#> 4      8    16 13.88      2.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = my_data.plot(x='speed', y='dist', style='o', legend=False)\n",
        "my_data.plot(x='speed', y='y_', style='-', legend=False, ax=ax)\n",
        "ax.vlines(x=X, ymin=y, ymax=y_, linestyles='dotted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_squared_error(y, y_)**0.5\n",
        "# \u3042\u308b\u3044\u306f\n",
        "(my_data['residual']**2).mean()**0.5\n",
        "\n",
        "#> 15.068855995791381"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.score(X, y)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "r2_score(y_true=y, y_pred=y_)\n",
        "#> 0.6510793807582509"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.6510793807582511"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test = my_data[:3]\n",
        "X = my_test[['speed']]\n",
        "y = my_test['dist']\n",
        "y_ = my_model.predict(X)\n",
        "\n",
        "my_model.score(X, y)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "r2_score(y_true=y, y_pred=y_)\n",
        "#> -4.498191310376778 # \u6c7a\u5b9a\u4fc2\u65701\n",
        "\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.0769230769230769 # \u6c7a\u5b9a\u4fc2\u65706"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "\n",
        "my_idx = [1, 10, 26, 33, 38, 43]\n",
        "my_sample = my_data.iloc[my_idx, ]\n",
        "X, y = my_sample[['speed']], my_sample['dist']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d = 5\n",
        "X5 = PolynomialFeatures(d, include_bias=False).fit_transform(X) # X\u306e1\u4e57\u304b\u30895\u4e57\u306e\u5909\u6570\n",
        "\n",
        "my_model = LinearRegression()\n",
        "my_model.fit(X5, y)\n",
        "y_ = my_model.predict(X5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "((y - y_)**2).mean()**0.5\n",
        "#> 7.725744805546204e-07 # RMSE\n",
        "\n",
        "my_model.score(X5, y)\n",
        "#> 0.9999999999999989 # \u6c7a\u5b9a\u4fc2\u65701\n",
        "\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.9999999999999991 # \u6c7a\u5b9a\u4fc2\u65706"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame({'speed': np.linspace(min(my_data.speed),\n",
        "                                         max(my_data.speed),\n",
        "                                         100)})\n",
        "X5 = PolynomialFeatures(d, include_bias=False).fit_transform(tmp)\n",
        "tmp['model'] = my_model.predict(X5)\n",
        "\n",
        "my_sample = my_sample.assign(sample=y)\n",
        "my_df = pd.concat([my_data, my_sample, tmp])\n",
        "my_df.plot(x='speed', style=['o', 'o', '-'], ylim=(0, 130))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u6e96\u5099\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "# \u8a13\u7df4\n",
        "my_model = KNeighborsRegressor()\n",
        "my_model.fit(X, y)\n",
        "\n",
        "# \u53ef\u8996\u5316\u306e\u6e96\u5099\n",
        "tmp = pd.DataFrame({'speed': np.linspace(min(my_data.speed),\n",
        "                                         max(my_data.speed),\n",
        "                                         100)})\n",
        "tmp['model'] = my_model.predict(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.concat([my_data, tmp]).plot(\n",
        "    x='speed', style=['o', '-'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = my_model.predict(X)\n",
        "\n",
        "((y - y_)**2).mean()**0.5\n",
        "#> 13.087184571174962 # RMSE\n",
        "\n",
        "my_model.score(X, y)\n",
        "#> 0.7368165812204317 # \u6c7a\u5b9a\u4fc2\u65701\n",
        "\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.7380949412509705 # \u6c7a\u5b9a\u4fc2\u65706"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# \u30c7\u30fc\u30bf\u306e\u6e96\u5099\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "# \u30e2\u30c7\u30eb\u306e\u6307\u5b9a\n",
        "my_model = LinearRegression()\n",
        "\n",
        "# \u691c\u8a3c\uff085\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\uff09\n",
        "my_scores = cross_val_score(my_model, X, y)\n",
        "\n",
        "# 5\u500b\u306e\u6c7a\u5b9a\u4fc2\u65701\u3092\u5f97\u308b\uff0e\n",
        "my_scores\n",
        "#> array([-0.25789256, -0.21421069, -0.30902773, -0.27346232,  0.02312918])\n",
        "\n",
        "# \u5e73\u5747\u3092\u6c7a\u5b9a\u4fc2\u65701\uff08\u691c\u8a3c\uff09\u3068\u3059\u308b\uff0e\n",
        "my_scores.mean()\n",
        "#> -0.20629282165364665"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scores = cross_val_score(my_model, X, y,\n",
        "                            scoring='neg_root_mean_squared_error')\n",
        "-my_scores.mean()\n",
        "#> 15.58402474583013 # RMSE\uff08\u691c\u8a3c\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "my_model = LinearRegression().fit(X, y)\n",
        "y_ = my_model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RMSE\uff08\u8a13\u7df4\uff09\n",
        "mean_squared_error(y, y_)**0.5\n",
        "#> 15.068855995791381\n",
        "\n",
        "# \u6c7a\u5b9a\u4fc2\u65701\uff08\u8a13\u7df4\uff09\n",
        "my_model.score(X, y)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "r2_score(y_true=y, y_pred=y_)\n",
        "#> 0.6510793807582509\n",
        "\n",
        "# \u6c7a\u5b9a\u4fc2\u65706\uff08\u8a13\u7df4\uff09\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.6510793807582511"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scores = cross_val_score(my_model, X, y,\n",
        "                            scoring='neg_root_mean_squared_error')\n",
        "-my_scores.mean()\n",
        "#> 15.301860331378464  # RMSE\uff08\u691c\u8a3c\uff09\n",
        "\n",
        "my_scores = cross_val_score(my_model, X, y, scoring='r2') # scoring='r2'\u306f\u7701\u7565\u53ef\n",
        "my_scores.mean()\n",
        "#> 0.49061365458235245 # \u6c7a\u5b9a\u4fc2\u65701\uff08\u691c\u8a3c\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u65b9\u6cd51\n",
        "my_scores1 = cross_val_score(my_model, X, y, cv=LeaveOneOut(),\n",
        "                             scoring='neg_mean_squared_error')\n",
        "(-my_scores1.mean())**0.5\n",
        "#> 15.697306009399101\n",
        "\n",
        "# \u65b9\u6cd52\n",
        "my_scores2 = cross_val_score(my_model, X, y, cv=LeaveOneOut(),\n",
        "                             scoring='neg_root_mean_squared_error')\n",
        "(my_scores2**2).mean()**0.5\n",
        "#> 15.697306009399101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "-my_scores2.mean()\n",
        "#> 12.059178648637483"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "my_lm_scores = cross_val_score(\n",
        "    LinearRegression(),\n",
        "    X, y, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
        "\n",
        "my_knn_socres = cross_val_score(\n",
        "    KNeighborsRegressor(n_neighbors=5),\n",
        "    X, y, cv=LeaveOneOut(), scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(-my_lm_scores.mean())**0.5\n",
        "#> 15.697306009399101 # \u7dda\u5f62\u56de\u5e30\u5206\u6790\n",
        "\n",
        "(-my_knn_socres.mean())**0.5\n",
        "#> 16.07308308943869 # K\u6700\u8fd1\u508d\u6cd5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df = pd.DataFrame({\n",
        "    'lm': -my_lm_scores,\n",
        "    'knn': -my_knn_socres})\n",
        "my_df.head()\n",
        "#>            lm     knn\n",
        "#> 0   18.913720  108.16\n",
        "#> 1  179.215044    0.64\n",
        "#> 2   41.034336   64.00\n",
        "#> 3  168.490212  184.96\n",
        "#> 4    5.085308    0.00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_df.boxplot().set_ylabel(\"$r^2$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.weightstats import DescrStatsW\n",
        "d = DescrStatsW(my_df.lm - my_df.knn)\n",
        "d.ttest_mean()[1] # p\u5024\n",
        "#> 0.6952755720536115\n",
        "\n",
        "d.tconfint_mean(alpha=0.05, alternative='two-sided') # \u4fe1\u983c\u533a\u9593\n",
        "#> (-72.8275283312228, 48.95036023665703)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "my_params = {'n_neighbors': range(1, 16)} # \u63a2\u7d22\u7bc4\u56f2\uff081\u4ee5\u4e0a16\u672a\u6e80\u306e\u6574\u6570\uff09\n",
        "\n",
        "my_search = GridSearchCV(estimator=KNeighborsRegressor(),\n",
        "                         param_grid=my_params,\n",
        "                         cv=LeaveOneOut(),\n",
        "                         scoring='neg_mean_squared_error')\n",
        "my_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_search.cv_results_                # \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a73\u7d30\n",
        "my_scores = (-tmp['mean_test_score'])**0.5 # RMSE\n",
        "my_results = pd.DataFrame(tmp['params']).assign(validation=my_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_results.head()\n",
        "#>    n_neighbors  validation\n",
        "#> 0            1   20.089798\n",
        "#> 1            2   17.577685\n",
        "#> 2            3   16.348836\n",
        "#> 3            4   16.198804\n",
        "#> 4            5   16.073083"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_results.plot(x='n_neighbors',\n",
        "                style='o-',\n",
        "                ylabel='RMSE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_search.best_params_\n",
        "#> {'n_neighbors': 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(-my_search.best_score_)**0.5\n",
        "#> 16.07308308943869"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = my_search.best_estimator_\n",
        "y_ = my_model.predict(X)\n",
        "mean_squared_error(y_, y)**0.5\n",
        "#> 13.087184571174962"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('cars', 'datasets').data\n",
        "X, y = my_data[['speed']], my_data['dist']\n",
        "\n",
        "def my_loocv(k):\n",
        "    my_model = KNeighborsRegressor(n_neighbors=k)\n",
        "    my_scores = cross_val_score(estimator=my_model, X=X, y=y,\n",
        "                                cv=LeaveOneOut(),\n",
        "                                scoring='neg_mean_squared_error')\n",
        "    y_ = my_model.fit(X, y).predict(X)\n",
        "    return pd.Series([k,\n",
        "                      (-my_scores.mean())**0.5,        # RMSE\uff08\u691c\u8a3c\uff09\n",
        "                      mean_squared_error(y_, y)**0.5], # RMSE\uff08\u8a13\u7df4\uff09\n",
        "                     index=['n_neighbors', 'validation', 'training'])\n",
        "\n",
        "my_results = pd.Series(range(1, 16)).apply(my_loocv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_results.plot(x='n_neighbors',\n",
        "                style='o-',\n",
        "                ylabel='RMSE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "my_url = 'http://www.liquidasset.com/winedata.html'\n",
        "tmp = pd.read_table(my_url, skiprows=62, nrows=38, sep='\\\\s+', na_values='.')\n",
        "tmp.describe()\n",
        "#>              OBS         VINT    LPRICE2       WRAIN    DEGREES ...\n",
        "#> count  38.000000    38.000000  27.000000   38.000000  37.000000 ...\n",
        "#> mean   19.500000  1970.500000  -1.451765  605.000000  16.522973 ...\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data = tmp.iloc[:, 2:].dropna()\n",
        "my_data.head()\n",
        "#>    LPRICE2  WRAIN  DEGREES ...\n",
        "#> 0 -0.99868    600  17.1167 ...\n",
        "#> 1 -0.45440    690  16.7333 ...\n",
        "#> 3 -0.80796    502  17.1500 ...\n",
        "#> 5 -1.50926    420  16.1333 ...\n",
        "#> 6 -1.71655    582  16.4167 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.shape\n",
        "#> (27, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.to_csv('wine.csv',\n",
        "               index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#my_data = pd.read_csv('wine.csv') # \u4f5c\u3063\u305f\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u3046\u5834\u5408\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "X, y = my_data.drop(columns=['LPRICE2']), my_data['LPRICE2']\n",
        "\n",
        "my_model = LinearRegression().fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.intercept_\n",
        "#> -12.145333576510417\n",
        "\n",
        "pd.Series(my_model.coef_,\n",
        "          index=X.columns)\n",
        "#> WRAIN      0.001167\n",
        "#> DEGREES    0.616392\n",
        "#> HRAIN     -0.003861\n",
        "#> TIME_SV    0.023847\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test = [[500, 17, 120, 2]]\n",
        "my_model.predict(my_test)\n",
        "#> array([-1.49884253])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = my_model.predict(X)\n",
        "\n",
        "mean_squared_error(y_, y)**0.5\n",
        "#> 0.2586166620130621 # RMSE\uff08\u8a13\u7df4\uff09\n",
        "\n",
        "my_model.score(X, y)\n",
        "#> 0.8275277990052154 # \u6c7a\u5b9a\u4fc2\u65701\n",
        "\n",
        "np.corrcoef(y, y_)[0, 1]**2\n",
        "#> 0.8275277990052158 # \u6c7a\u5b9a\u4fc2\u65706"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scores = cross_val_score(my_model, X, y,\n",
        "                            cv=LeaveOneOut(),\n",
        "                            scoring='neg_mean_squared_error')\n",
        "(-my_scores.mean())**0.5\n",
        "#> 0.32300426518411957 # RMSE\uff08\u691c\u8a3c\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "M = np.matrix(X.assign(b0=1))\n",
        "b = np.linalg.pinv(M) @ y\n",
        "pd.Series(b,\n",
        "    index=list(X.columns) + ['b0'])\n",
        "#> WRAIN       0.001167\n",
        "#> DEGREES     0.616392\n",
        "#> HRAIN      -0.003861\n",
        "#> TIME_SV     0.023847\n",
        "#> b0        -12.145334\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "X, y = my_data.drop(columns=['LPRICE2']), my_data['LPRICE2']\n",
        "\n",
        "# StandardScaler\u3067\u6a19\u6e96\u5316\u3057\u305f\u7d50\u679c\u3092\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u623b\u3057\u3066\u304b\u3089\u63cf\u753b\u3059\u308b\uff0e\n",
        "pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns\n",
        "            ).boxplot(showmeans=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_pipeline = Pipeline([\n",
        "    ('sc', StandardScaler()),\n",
        "    ('lr', LinearRegression())])\n",
        "my_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u7dda\u5f62\u56de\u5e30\u306e\u90e8\u5206\u3060\u3051\u3092\u53d6\u308a\u51fa\u3059\uff0e\n",
        "my_lr = my_pipeline.named_steps.lr\n",
        "my_lr.intercept_\n",
        "#> -1.4517651851851847\n",
        "\n",
        "pd.Series(my_lr.coef_,\n",
        "          index=X.columns)\n",
        "#> WRAIN      0.147741\n",
        "#> DEGREES    0.398724\n",
        "#> HRAIN     -0.276802\n",
        "#> TIME_SV    0.192979\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test = [[500, 17, 120, 2]]\n",
        "my_pipeline.predict(my_test)\n",
        "#> array([-1.49884253])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "\n",
        "n = len(my_data)\n",
        "my_data2 = my_data.assign(v1=[i % 2 for i in range(n)],\n",
        "                          v2=[i % 3 for i in range(n)])\n",
        "my_data2.head()\n",
        "#>    LPRICE2  WRAIN  DEGREES  HRAIN  TIME_SV  v1  v2\n",
        "#> 0 -0.99868    600  17.1167    160       31   0   0\n",
        "#> 1 -0.45440    690  16.7333     80       30   1   1\n",
        "#> 2 -0.80796    502  17.1500    130       28   0   2\n",
        "#> 3 -1.50926    420  16.1333    110       26   1   0\n",
        "#> 4 -1.71655    582  16.4167    187       25   0   1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = my_data2.drop(columns=['LPRICE2']), my_data2['LPRICE2']\n",
        "my_model2 = LinearRegression().fit(X, y)\n",
        "\n",
        "y_ = my_model2.predict(X)\n",
        "mean_squared_error(y_, y)**0.5\n",
        "#> 0.2562120047505748 # RMSE\uff08\u8a13\u7df4\uff09\n",
        "\n",
        "my_scores = cross_val_score(my_model2, X, y,\n",
        "                            cv=LeaveOneOut(),\n",
        "                            scoring='neg_mean_squared_error')\n",
        "(-my_scores.mean())**0.5\n",
        "#> 0.3569918035928941 # RMSE\uff08\u691c\u8a3c\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "\n",
        "n = len(my_data)\n",
        "my_data2 = my_data.assign(v1=[i % 2 for i in range(n)],\n",
        "                          v2=[i % 3 for i in range(n)])\n",
        "X, y = my_data2.drop(columns=['LPRICE2']), my_data2['LPRICE2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_sfs = SequentialFeatureSelector(\n",
        "    estimator=LinearRegression(),\n",
        "    direction='forward', # \u5909\u6570\u5897\u52a0\u6cd5\n",
        "    cv=LeaveOneOut(),\n",
        "    scoring='neg_mean_squared_error')\n",
        "\n",
        "my_pipeline = Pipeline([         # \u5909\u6570\u9078\u629e\u306e\u5f8c\u3067\u518d\u8a13\u7df4\u3092\u884c\u3046\u3088\u3046\u306b\u3059\u308b\uff0e\n",
        "    ('sfs', my_sfs),             # \u5909\u6570\u9078\u629e\n",
        "    ('lr', LinearRegression())]) # \u56de\u5e30\u5206\u6790\n",
        "\n",
        "my_params = {'sfs__n_features_to_select': range(1, 6)} # \u9078\u629e\u3059\u308b\u5909\u6570\u306e\u4e0a\u9650\n",
        "my_search = GridSearchCV(estimator=my_pipeline,\n",
        "                         param_grid=my_params,\n",
        "                         cv=LeaveOneOut(),\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         n_jobs=-1).fit(X, y)\n",
        "my_model = my_search.best_estimator_ # \u6700\u826f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u518d\u8a13\u7df4\u3057\u305f\u30e2\u30c7\u30eb\n",
        "my_search.best_estimator_.named_steps.sfs.get_support()\n",
        "#> array([ True,  True,  True,  True, False, False])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.linear_model import ElasticNet, enet_path\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import zscore\n",
        "warnings.simplefilter('ignore', ConvergenceWarning) # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3057\u306a\u3044\uff0e\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "X, y = my_data.drop(columns=['LPRICE2']), my_data['LPRICE2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A = 2\n",
        "B = 0.1\n",
        "\n",
        "my_pipeline = Pipeline([\n",
        "    ('sc', StandardScaler()),\n",
        "    ('enet', ElasticNet(\n",
        "        alpha=A,\n",
        "        l1_ratio=B))])\n",
        "my_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_enet = my_pipeline.named_steps.enet\n",
        "my_enet.intercept_\n",
        "#> -1.4517651851851852\n",
        "\n",
        "pd.Series(my_enet.coef_,\n",
        "          index=X.columns)\n",
        "#> WRAIN      0.000000\n",
        "#> DEGREES    0.074101\n",
        "#> HRAIN     -0.041159\n",
        "#> TIME_SV    0.024027\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test = pd.DataFrame(\n",
        "    [[500, 17, 120, 2]])\n",
        "my_pipeline.predict(my_test)\n",
        "#> array([-1.41981616])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "As = np.e**np.arange(2, -5.5, -0.1)\n",
        "B = 0.1\n",
        "\n",
        "_, my_path, _ = enet_path(\n",
        "    zscore(X), zscore(y),\n",
        "    alphas=As,\n",
        "    l1_ratio=B)\n",
        "\n",
        "pd.DataFrame(\n",
        "    my_path.T,\n",
        "    columns=X.columns,\n",
        "    index=np.log(As)\n",
        ").plot(\n",
        "    xlabel='log A ( = log alpha)',\n",
        "    ylabel='Coefficients')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "As = np.linspace(0, 0.1, 21)\n",
        "Bs = np.linspace(0, 0.1,  6)\n",
        "\n",
        "my_pipeline = Pipeline([('sc', StandardScaler()),\n",
        "                        ('enet', ElasticNet())])\n",
        "my_search = GridSearchCV(\n",
        "    estimator=my_pipeline,\n",
        "    param_grid={'enet__alpha': As, 'enet__l1_ratio': Bs},\n",
        "    cv=LeaveOneOut(),\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1).fit(X, y)\n",
        "my_model = my_search.best_estimator_ # \u6700\u826f\u30e2\u30c7\u30eb\n",
        "\n",
        "my_search.best_params_               # \u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf\n",
        "#> {'enet__alpha': 0.075, 'enet__l1_ratio': 0.0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_search.cv_results_                # \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u8a73\u7d30\n",
        "my_scores = (-tmp['mean_test_score'])**0.5 # RMSE\n",
        "\n",
        "my_results = pd.DataFrame(tmp['params']).assign(RMSE=my_scores).pivot(\n",
        "    index='enet__alpha',\n",
        "    columns='enet__l1_ratio',\n",
        "    values='RMSE')\n",
        "\n",
        "my_results.plot(style='o-', xlabel='A ( = alpha)', ylabel='RMSE').legend(\n",
        "    title='B ( = l1_ratio)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(-my_search.best_score_)**0.5\n",
        "#> 0.31945619679509646"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "x = np.linspace(-6, 6, 100)\n",
        "y = 1 / (1 + np.exp(-x))\n",
        "plt.plot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "X, y = my_data.drop(columns=['LPRICE2']), my_data['LPRICE2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.simplefilter(\"ignore\", ConvergenceWarning)  # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3057\u306a\u3044\uff0e\n",
        "my_pipeline = Pipeline([('sc', StandardScaler()),    # \u6a19\u6e96\u5316\n",
        "                        ('mlp', MLPRegressor())])    # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n",
        "my_pipeline.fit(X, y)                                # \u8a13\u7df4\n",
        "\n",
        "my_scores = cross_val_score(my_pipeline, X, y, cv=LeaveOneOut(),\n",
        "                            scoring='neg_mean_squared_error')\n",
        "warnings.simplefilter(\"default\", ConvergenceWarning) # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3059\u308b\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(-my_scores.mean())**0.5\n",
        "#> 0.41735891601426384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_pipeline = Pipeline([\n",
        "    ('sc', StandardScaler()),\n",
        "    ('mlp', MLPRegressor(tol=1e-5,         # \u6539\u5584\u3057\u305f\u3068\u898b\u306a\u3059\u57fa\u6e96\n",
        "                         max_iter=5000))]) # \u6539\u5584\u3057\u306a\u304f\u306a\u308b\u307e\u3067\u306e\u53cd\u5fa9\u6570\n",
        "my_layers = (1, 3, 5,                                         # \u96a0\u308c\u5c641\u5c64\u306e\u5834\u5408\n",
        "             (1, 1), (3, 1), (5, 1), (1, 2), (3, 2), (5, 2))  # \u96a0\u308c\u5c642\u5c64\u306e\u5834\u5408\n",
        "my_params = {'mlp__hidden_layer_sizes': my_layers}\n",
        "my_search = GridSearchCV(estimator=my_pipeline,\n",
        "                         param_grid=my_params,\n",
        "                         cv=LeaveOneOut(),\n",
        "                         scoring='neg_mean_squared_error',\n",
        "                         n_jobs=-1).fit(X, y)\n",
        "my_model = my_search.best_estimator_ # \u6700\u826f\u30e2\u30c7\u30eb\n",
        "\n",
        "my_search.best_params_               # \u6700\u826f\u30d1\u30e9\u30e1\u30fc\u30bf\n",
        "#> {'mlp__hidden_layer_sizes': 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(-my_search.best_score_)**0.5\n",
        "#> 0.3759690731968538"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "my_data.head()\n",
        "#>    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
        "#> 0           5.1          3.5           1.4          0.2  setosa\n",
        "#> 1           4.9          3.0           1.4          0.2  setosa\n",
        "#> 2           4.7          3.2           1.3          0.2  setosa\n",
        "#> 3           4.6          3.1           1.5          0.2  setosa\n",
        "#> 4           5.0          3.6           1.4          0.2  setosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.describe()\n",
        "#>        Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
        "#> count    150.000000   150.000000    150.000000   150.000000\n",
        "#> mean       5.843333     3.057333      3.758000     1.199333\n",
        "# \u4ee5\u4e0b\u7701\u7565"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import graphviz\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn import tree\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species\n",
        "\n",
        "my_model = tree.DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "my_model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_dot = tree.export_graphviz(\n",
        "    decision_tree=my_model,\n",
        "    out_file=None,                 # \u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\u3057\u306a\u3044\uff0e\n",
        "    feature_names=X.columns,       # \u5909\u6570\u540d\n",
        "    class_names=my_model.classes_, # \u30ab\u30c6\u30b4\u30ea\u540d\n",
        "    filled=True)                   # \u8272\u3092\u5857\u308b\uff0e\n",
        "graphviz.Source(my_dot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test = pd.DataFrame([[5.0, 3.5, 1.5, 0.5],\n",
        "                        [6.5, 3.0, 5.0, 2.0]])\n",
        "my_model.predict(my_test)\n",
        "#> array(['setosa', 'virginica'], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(\n",
        "    my_model.predict_proba(my_test),\n",
        "    columns=my_model.classes_)\n",
        "#>    setosa  versicolor  virginica\n",
        "#> 0     1.0    0.000000   0.000000\n",
        "#> 1     0.0    0.021739   0.978261"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import graphviz\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, LeaveOneOut\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species\n",
        "\n",
        "my_model = tree.DecisionTreeClassifier(max_depth=2, random_state=0).fit(X, y)\n",
        "y_ = my_model.predict(X)\n",
        "confusion_matrix(y_true=y, y_pred=y_)\n",
        "#> array([[50,  0,  0],\n",
        "#>        [ 0, 49,  1],\n",
        "#>        [ 0,  5, 45]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.score(X, y)\n",
        "# \u3042\u308b\u3044\u306f\n",
        "y_ = my_model.predict(X)\n",
        "(y_ == y).mean()\n",
        "\n",
        "#> 0.96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_val_score(my_model, X, y, cv=LeaveOneOut()).mean()\n",
        "#> 0.9533333333333334"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_search = GridSearchCV(estimator=tree.DecisionTreeClassifier(random_state=0),\n",
        "                         param_grid={'max_depth': range(1, 11)},\n",
        "                         cv=LeaveOneOut(),\n",
        "                         n_jobs=-1).fit(X, y)\n",
        "my_search.best_params_, my_search.best_score_\n",
        "#> ({'max_depth': 2}, 0.9533333333333334)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_params = {\n",
        "    'max_depth': range(2, 6),\n",
        "    'min_samples_split': [2, 20],\n",
        "    'min_samples_leaf': range(1, 8)}\n",
        "\n",
        "my_search = GridSearchCV(\n",
        "    estimator=tree.DecisionTreeClassifier(min_impurity_decrease=0.01,\n",
        "                                          random_state=0),\n",
        "    param_grid=my_params,\n",
        "    cv=LeaveOneOut(),\n",
        "    n_jobs=-1).fit(X, y)\n",
        "my_search.best_params_, my_search.best_score_\n",
        "#> ({'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
        "#>  0.9733333333333334)\n",
        "\n",
        "tmp = my_search.cv_results_\n",
        "my_results = pd.DataFrame(tmp['params']).assign(\n",
        "    Accuracy=tmp['mean_test_score'])\n",
        "# \u6b63\u89e3\u7387\uff08\u691c\u8a3c\uff09\u306e\u6700\u5927\u5024\n",
        "my_results[my_results.Accuracy == my_results.Accuracy.max()]\n",
        "#>     max_depth  min_samples_leaf  min_samples_split  Accuracy\n",
        "#> 22          3                 5                  2  0.973333\n",
        "#> 23          3                 5                 20  0.973333\n",
        "#> 36          4                 5                  2  0.973333\n",
        "#> 37          4                 5                 20  0.973333\n",
        "#> 50          5                 5                  2  0.973333\n",
        "#> 51          5                 5                 20  0.973333"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = my_search.best_estimator_\n",
        "my_dot = tree.export_graphviz(\n",
        "    decision_tree=my_model,\n",
        "    out_file=None,\n",
        "    feature_names=X.columns,\n",
        "    class_names=my_model.classes_,\n",
        "    filled=True)\n",
        "graphviz.Source(my_dot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "import xgboost\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species\n",
        "label_encoder = LabelEncoder(); y = label_encoder.fit_transform(y)\n",
        "\n",
        "my_search = GridSearchCV(RandomForestClassifier(),\n",
        "                         param_grid={'max_features': [2, 3, 4]},\n",
        "                         cv=LeaveOneOut(),\n",
        "                         n_jobs=-1).fit(X, y)\n",
        "my_search.best_params_\n",
        "#> {'max_features': 2}\n",
        "\n",
        "my_search.cv_results_['mean_test_score']\n",
        "#> array([0.96      , 0.96      , 0.95333333])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.simplefilter('ignore') # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3057\u306a\u3044\uff0e\n",
        "my_search = GridSearchCV(\n",
        "    xgboost.XGBClassifier(eval_metric='mlogloss'),\n",
        "    param_grid={'n_estimators'    : [50, 100, 150],\n",
        "                'max_depth'       : [1, 2, 3],\n",
        "                'learning_rate'   : [0.3, 0.4],\n",
        "                'gamma'           : [0],\n",
        "                'colsample_bytree': [0.6, 0.8],\n",
        "                'min_child_weight': [1],\n",
        "                'subsample'       : [0.5, 0.75, 1]},\n",
        "    cv=5, # 5\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\n",
        "    n_jobs=1).fit(X, y) # n_jobs=-1\u3067\u306f\u306a\u3044\uff0e\n",
        "warnings.simplefilter('default') # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3059\u308b\uff0e\n",
        "\n",
        "my_search.best_params_\n",
        "#> {'colsample_bytree': 0.6,\n",
        "#>  'gamma': 0,\n",
        "#>  'learning_rate': 0.3,\n",
        "#>  'max_depth': 1,\n",
        "#>  'min_child_weight': 1,\n",
        "#>  'n_estimators': 50,\n",
        "#>  'subsample': 0.75}\n",
        "\n",
        "my_search.best_score_\n",
        "#> 0.9666666666666668"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = RandomForestClassifier().fit(X, y)\n",
        "tmp = pd.Series(my_model.feature_importances_, index=X.columns)\n",
        "tmp.sort_values().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "import xgboost\n",
        "from sklearn import tree\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "\n",
        "n = len(my_data)\n",
        "my_data['Petal.Length'] = [np.nan if i % 10 == 0 else\n",
        "                           my_data['Petal.Length'][i] for i in range(n)]\n",
        "my_data['Petal.Width']  = [np.nan if i % 10 == 1 else\n",
        "                           my_data['Petal.Width'][i]  for i in range(n)]\n",
        "\n",
        "my_data.describe() # count\u306e\u5024\u304c135\u306e\u5909\u6570\u306b\uff0c150-135=15\u500b\u306e\u6b20\u640d\u304c\u3042\u308b\uff0e\n",
        "#>        Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
        "#> count    150.000000   150.000000    135.000000   135.000000\n",
        "#> mean       5.843333     3.057333      3.751852     1.197037\n",
        "# \u4ee5\u4e0b\u7701\u7565\n",
        "\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')), # \u6b20\u640d\u3092\u4e2d\u592e\u5024\u3067\u57cb\u3081\u308b\uff0e\n",
        "    ('tree', tree.DecisionTreeClassifier(random_state=0))])\n",
        "my_scores = cross_val_score(my_pipeline, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
        "my_scores.mean()\n",
        "#> 0.9333333333333333"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "warnings.simplefilter('ignore')  # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3057\u306a\u3044\uff0e\n",
        "my_scores = cross_val_score(\n",
        "    xgboost.XGBClassifier(eval_metric='mlogloss'), X, y, cv=5)\n",
        "warnings.simplefilter('default') # \u3053\u308c\u4ee5\u964d\uff0c\u8b66\u544a\u3092\u8868\u793a\u3059\u308b\uff0e\n",
        "\n",
        "my_scores.mean()\n",
        "#> 0.9666666666666668"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species\n",
        "\n",
        "my_scores = cross_val_score(KNeighborsClassifier(), X, y, cv=LeaveOneOut())\n",
        "my_scores.mean()\n",
        "#> 0.9666666666666667"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "my_data = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "X, y = my_data.iloc[:, 0:4], my_data.Species\n",
        "\n",
        "my_pipeline = Pipeline([('sc',  StandardScaler()),              # \u6a19\u6e96\u5316\n",
        "                        ('mlp', MLPClassifier(max_iter=1000))]) # \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\n",
        "my_scores = cross_val_score(my_pipeline, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
        "my_scores.mean()\n",
        "#> 0.9533333333333334"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y       = np.array([  0,   1,   1,   0,   1,   0,    1,   0,   0,   1])\n",
        "y_score = np.array([0.7, 0.8, 0.3, 0.4, 0.9, 0.6, 0.99, 0.1, 0.2, 0.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = np.array([1 if 0.5 <= p else 0 for p in y_score])\n",
        "y_\n",
        "#> array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y_true=y, y_pred=y_)\n",
        "#> array([[3, 2],\n",
        "#>        [1, 4]])\n",
        "\n",
        "print(classification_report(y_true=y, y_pred=y_))\n",
        "#>               precision    recall  f1-score   support\n",
        "#>\n",
        "#>            0       0.75      0.60      0.67         5\n",
        "#>            1       0.67      0.80      0.73         5\n",
        "#>\n",
        "#>     accuracy                           0.70        10\n",
        "#>    macro avg       0.71      0.70      0.70        10\n",
        "#> weighted avg       0.71      0.70      0.70        10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (roc_curve, RocCurveDisplay,\n",
        "    precision_recall_curve, PrecisionRecallDisplay, auc)\n",
        "\n",
        "y       = np.array([  0,   1,   1,   0,   1,   0,    1,   0,   0,   1])\n",
        "y_score = np.array([0.7, 0.8, 0.3, 0.4, 0.9, 0.6, 0.99, 0.1, 0.2, 0.5])\n",
        "y_      = np.array([1 if 0.5 <= p else 0 for p in y_score])\n",
        "\n",
        "[sum((y == 0) & (y_ == 1)) / sum(y == 0), # FPR\n",
        " sum((y == 1) & (y_ == 1)) / sum(y == 1)] # TPR\n",
        "#> [0.4, 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_fpr, my_tpr, _ = roc_curve(y_true=y,\n",
        "                              y_score=y_score,\n",
        "                              pos_label=1) # 1\u304c\u967d\u6027\u3067\u3042\u308b\uff0e\n",
        "RocCurveDisplay(fpr=my_fpr, tpr=my_tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc(x=my_fpr, y=my_tpr)\n",
        "#> 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[sum((y == 1) & (y_ == 1)) / sum(y  == 1), # Recall == TPR\n",
        " sum((y == 1) & (y_ == 1)) / sum(y_ == 1)] # Precision\n",
        "#> [0.8, 0.6666666666666666]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_precision, my_recall, _ = precision_recall_curve(y_true=y,\n",
        "                                                    probas_pred=y_score,\n",
        "                                                    pos_label=1)\n",
        "PrecisionRecallDisplay(precision=my_precision, recall=my_recall).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc(x=my_recall, y=my_precision)\n",
        "#> 0.8463095238095237"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import graphviz\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import roc_curve, RocCurveDisplay, auc\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/titanic.csv')\n",
        "my_data = pd.read_csv(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data.head()\n",
        "#>   Class   Sex    Age Survived\n",
        "#> 0   1st  Male  Child      Yes\n",
        "#> 1   1st  Male  Child      Yes\n",
        "#> 2   1st  Male  Child      Yes\n",
        "#> 3   1st  Male  Child      Yes\n",
        "#> 4   1st  Male  Child      Yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = my_data.iloc[:, 0:3], my_data.Survived\n",
        "\n",
        "my_pipeline = Pipeline([\n",
        "    ('ohe', OneHotEncoder(drop='first')),\n",
        "    ('tree', tree.DecisionTreeClassifier(max_depth=2, random_state=0,\n",
        "                                         min_impurity_decrease=0.01))])\n",
        "my_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_enc  = my_pipeline.named_steps['ohe']  # \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u304b\u3089\u30a8\u30f3\u30b3\u30fc\u30c0\u3092\u53d6\u308a\u51fa\u3059\uff0e\n",
        "my_tree = my_pipeline.named_steps['tree'] # \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u304b\u3089\u6728\u3092\u53d6\u308a\u51fa\u3059\uff0e\n",
        "\n",
        "my_dot = tree.export_graphviz(\n",
        "    decision_tree=my_tree,\n",
        "    out_file=None,\n",
        "    feature_names=my_enc.get_feature_names() \\\n",
        "    if hasattr(my_enc, 'get_feature_names') else my_enc.get_feature_names_out(),\n",
        "    class_names=my_pipeline.classes_,\n",
        "    filled=True)\n",
        "graphviz.Source(my_dot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scores = cross_val_score(\n",
        "    my_pipeline, X, y,\n",
        "    cv=LeaveOneOut(),\n",
        "    n_jobs=-1)\n",
        "my_scores.mean()\n",
        "#> 0.7832803271240345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame(\n",
        "    my_pipeline.predict_proba(X),\n",
        "    columns=my_pipeline.classes_)\n",
        "y_score = tmp.Yes\n",
        "\n",
        "my_fpr, my_tpr, _ = roc_curve(y_true=y,\n",
        "                              y_score=y_score,\n",
        "                              pos_label='Yes')\n",
        "my_auc = auc(x=my_fpr, y=my_tpr)\n",
        "my_auc\n",
        "#> 0.7114886868858494\n",
        "\n",
        "RocCurveDisplay(fpr=my_fpr, tpr=my_tpr, roc_auc=my_auc).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(-6, 6, 0.1)\n",
        "y = 1 / (1 + np.exp(-x))\n",
        "plt.plot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/titanic.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "\n",
        "X, y = my_data.iloc[:, 0:3], my_data.Survived\n",
        "\n",
        "my_pipeline = Pipeline([('ohe', OneHotEncoder(drop='first')),\n",
        "                        ('lr', LogisticRegression(penalty='none'))])\n",
        "my_pipeline.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_ohe = my_pipeline.named_steps.ohe\n",
        "my_lr  = my_pipeline.named_steps.lr\n",
        "\n",
        "my_lr.intercept_[0]\n",
        "#> 2.043878162056783\n",
        "\n",
        "tmp = my_ohe.get_feature_names() \\\n",
        "if hasattr(my_ohe, 'get_feature_names') \\\n",
        "else my_ohe.get_feature_names_out()\n",
        "pd.Series(my_lr.coef_[0],\n",
        "          index=tmp)\n",
        "#> x0_2nd     -1.018069\n",
        "#> x0_3rd     -1.777746\n",
        "#> x0_Crew    -0.857708\n",
        "#> x1_Male    -2.420090\n",
        "#> x2_Child    1.061531\n",
        "#> dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scores = cross_val_score(\n",
        "    my_pipeline, X, y,\n",
        "    cv=LeaveOneOut(),\n",
        "    n_jobs=-1)\n",
        "my_scores.mean()\n",
        "#> 0.7782825988187188"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import activations, callbacks, layers, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "tmp = pd.read_csv(my_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data = shuffle(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scaler = StandardScaler()\n",
        "X = my_scaler.fit_transform(\n",
        "    my_data.drop(columns=['LPRICE2']))\n",
        "y = my_data['LPRICE2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.linspace(-3, 3, 100)\n",
        "plt.plot(x, activations.relu(x))\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Dense(units=3, activation='relu', input_shape=[4]))\n",
        "my_model.add(layers.Dense(units=1))\n",
        "\n",
        "my_model.summary() # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u6982\u8981\n",
        "#> Model: \"sequential\"\n",
        "#> _________________________________________________________________\n",
        "#> Layer (type)                 Output Shape              Param #\n",
        "#> =================================================================\n",
        "#> dense (Dense)                (None, 3)                 15\n",
        "#> _________________________________________________________________\n",
        "#> dense_1 (Dense)              (None, 1)                 4\n",
        "#> =================================================================\n",
        "#> Total params: 19\n",
        "#> Trainable params: 19\n",
        "#> Non-trainable params: 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.compile(\n",
        "    loss='mse',\n",
        "    optimizer='rmsprop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_cb = callbacks.EarlyStopping(\n",
        "    patience=20,\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_history = my_model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    validation_split=0.25,\n",
        "    batch_size=10,\n",
        "    epochs=500,\n",
        "    callbacks=[my_cb],\n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame(my_history.history)\n",
        "tmp.plot(xlabel='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp.iloc[-1, ]\n",
        "#> loss        0.192743\n",
        "#> val_loss    0.342249\n",
        "#> Name: 499, dtype: float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = my_model.predict(X)\n",
        "((y_.ravel() - y)**2).mean()\n",
        "#> 0.23050613964540986"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from keras import callbacks, layers, losses, models\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "tmp = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "my_data = shuffle(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_scaler = StandardScaler()\n",
        "X = my_scaler.fit_transform(\n",
        "    my_data.drop(columns=['Species']))\n",
        "my_enc = LabelEncoder()\n",
        "y = my_enc.fit_transform(\n",
        "    my_data['Species'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Dense(units=3, activation='relu', input_shape=[4]))\n",
        "my_model.add(layers.Dense(units=3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                 optimizer='rmsprop',\n",
        "                 metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_cb = callbacks.EarlyStopping(\n",
        "    patience=20,\n",
        "    restore_best_weights=True)\n",
        "\n",
        "my_history = my_model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    validation_split=0.25,\n",
        "    batch_size=10,\n",
        "    epochs=500,\n",
        "    callbacks=[my_cb],\n",
        "    verbose=0)\n",
        "\n",
        "tmp = pd.DataFrame(my_history.history)\n",
        "tmp.plot(xlabel='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp.iloc[-1, ]\n",
        "#> loss            0.067497\n",
        "#> accuracy        0.973214\n",
        "#> val_loss        0.143529\n",
        "#> val_accuracy    0.921053"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_model.predict(X)\n",
        "y_ = np.argmax(tmp, axis=-1)\n",
        "(y_ == y).mean()\n",
        "#> 0.96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "-np.log([0.8, 0.7, 0.3, 0.8]).mean()\n",
        "#> 0.5017337127232719\n",
        "\n",
        "-np.log([0.7, 0.6, 0.2, 0.7]).mean()\n",
        "#> 0.708403356019389"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = [2, 1, 0, 1]\n",
        "y_1 = [[0.1, 0.1, 0.8],\n",
        "       [0.1, 0.7, 0.2],\n",
        "       [0.3, 0.4, 0.3],\n",
        "       [0.1, 0.8, 0.1]]\n",
        "y_2 = [[0.1, 0.2, 0.7],\n",
        "       [0.2, 0.6, 0.2],\n",
        "       [0.2, 0.5, 0.3],\n",
        "       [0.2, 0.7, 0.1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_1).numpy().mean(),\n",
        " losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_2).numpy().mean()]\n",
        "#> [0.5017337, 0.70840335]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from random import sample\n",
        "from keras import callbacks, layers, models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train.shape\n",
        "#> (60000, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.set_printoptions(linewidth=170)\n",
        "x_train[4, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.matshow(x_train[4, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train\n",
        "#> array([5, 0, 4, ..., 5, 6, 8],\n",
        "#>       dtype=uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train.min(), x_train.max()\n",
        "#> (0, 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_test  = x_test  / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_index = sample(range(60000), 6000)\n",
        "x_train = x_train[my_index, :, :]\n",
        "y_train = y_train[my_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Flatten(input_shape=[28, 28]))\n",
        "my_model.add(layers.Dense(units=256, activation=\"relu\"))\n",
        "my_model.add(layers.Dense(units=10, activation=\"softmax\"))\n",
        "\n",
        "my_model.summary()\n",
        "#> Model: \"sequential\"\n",
        "#> _________________________________________________________________\n",
        "#> Layer (type)                 Output Shape              Param #\n",
        "#> =================================================================\n",
        "#> flatten (Flatten)            (None, 784)               0\n",
        "#> _________________________________________________________________\n",
        "#> dense (Dense)                (None, 256)               200960\n",
        "#> _________________________________________________________________\n",
        "#> dense_1 (Dense)              (None, 10)                2570\n",
        "#> =================================================================\n",
        "#> Total params: 203,530\n",
        "#> Trainable params: 203,530\n",
        "#> Non-trainable params: 0\n",
        "#> _________________________________________________________________\n",
        "\n",
        "my_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                 optimizer='rmsprop',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "my_cb = callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_history = my_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    callbacks=[my_cb],\n",
        "    verbose=0)\n",
        "\n",
        "tmp = pd.DataFrame(my_history.history)\n",
        "tmp.plot(xlabel='epoch', style='o-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_model.predict(x_test)\n",
        "y_ = np.argmax(tmp, axis=-1)\n",
        "confusion_matrix(y_true=y_test,\n",
        "                 y_pred=y_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#> [[ 962    0    2    1    1    2    7    1    2    2]\n",
        "#>  [   0 1123    4    0    0    1    3    0    4    0]\n",
        "#>  [  11    4  954   11    6    2    7    9   26    2]\n",
        "#>  [   3    0   20  930    2   12    2   11   21    9]\n",
        "#>  [   1    1    7    0  927    1   11    1    5   28]\n",
        "#>  [  10    1    3   16    4  812   11    7   24    4]\n",
        "#>  [   9    3    4    0    9   10  919    0    4    0]\n",
        "#>  [   3    6   17    4   11    0    0  965    2   20]\n",
        "#>  [   8    4    6   12    6    9    9    7  901   12]\n",
        "#>  [   9    8    0    8   31    4    1   14    7  927]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(y_ == y_test).mean()\n",
        "#> 0.942"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.evaluate(x=x_test, y=y_test)\n",
        "#> [0.20125965774059296,\n",
        "#>  0.9419999718666077]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train2d = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test2d = x_test.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Conv2D(filters=32, kernel_size=3, # \u7573\u307f\u8fbc\u307f\u5c64\n",
        "                           activation='relu',\n",
        "                           input_shape=[28, 28, 1]))\n",
        "my_model.add(layers.MaxPooling2D(pool_size=2))        # \u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\n",
        "my_model.add(layers.Flatten())\n",
        "my_model.add(layers.Dense(128, activation='relu'))\n",
        "my_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "my_model.summary()\n",
        "#> Model: \"sequential\"\n",
        "#> _________________________________________________________________\n",
        "#> Layer (type)                 Output Shape              Param #\n",
        "#> =================================================================\n",
        "#> conv2d (Conv2D)              (None, 26, 26, 32)        320\n",
        "#> _________________________________________________________________\n",
        "#> max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0\n",
        "#> _________________________________________________________________\n",
        "#> flatten (Flatten)            (None, 5408)              0\n",
        "#> _________________________________________________________________\n",
        "#> dense (Dense)                (None, 128)               692352\n",
        "#> _________________________________________________________________\n",
        "#> dense_1 (Dense)              (None, 10)                1290\n",
        "#> =================================================================\n",
        "#> Total params: 693,962\n",
        "#> Trainable params: 693,962\n",
        "#> Non-trainable params: 0\n",
        "#> _________________________________________________________________\n",
        "\n",
        "my_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                 optimizer='rmsprop',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "my_cb = EarlyStopping(patience=5,\n",
        "                      restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_history = my_model.fit(\n",
        "    x=x_train2d,\n",
        "    y=y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    callbacks=my_cb,\n",
        "    verbose=0)\n",
        "\n",
        "tmp = pd.DataFrame(my_history.history)\n",
        "tmp.plot(xlabel='epoch', style='o-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.evaluate(x=x_test2d, y=y_test)\n",
        "#> [0.1359061449766159,\n",
        "#>  0.9581000208854675]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Conv2D(filters=20, kernel_size=5, activation='relu',\n",
        "                           input_shape=(28, 28, 1)))\n",
        "my_model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "my_model.add(layers.Conv2D(filters=20, kernel_size=5, activation='relu'))\n",
        "my_model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "my_model.add(layers.Dropout(rate=0.25))\n",
        "my_model.add(layers.Flatten())\n",
        "my_model.add(layers.Dense(500, activation='relu'))\n",
        "my_model.add(layers.Dropout(rate=0.5))\n",
        "my_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "my_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                 optimizer='rmsprop',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "my_cb = callbacks.EarlyStopping(patience=5,\n",
        "                                restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_history = my_model.fit(\n",
        "    x=x_train2d,\n",
        "    y=y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    callbacks=my_cb,\n",
        "    verbose=0)\n",
        "\n",
        "tmp = pd.DataFrame(my_history.history)\n",
        "tmp.plot(xlabel='epoch', style='o-')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.evaluate(x=x_test2d, y=y_test)\n",
        "#> [0.06491111218929291,\n",
        "#>  0.9797000288963318]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_prob = my_model.predict(x_test2d)                    # \u30ab\u30c6\u30b4\u30ea\u306b\u5c5e\u3059\u308b\u78ba\u7387\n",
        "\n",
        "tmp = pd.DataFrame({\n",
        "    'y_prob': np.max(y_prob, axis=1),                  # \u78ba\u7387\u306e\u6700\u5927\u5024\n",
        "    'y_': np.argmax(y_prob, axis=1),                   # \u4e88\u6e2c\u30ab\u30c6\u30b4\u30ea\n",
        "    'y': y_test,                                       # \u6b63\u89e3\n",
        "    'id': range(len(y_test))})                         # \u756a\u53f7\n",
        "\n",
        "tmp = tmp[tmp.y_ != tmp.y]                             # \u4e88\u6e2c\u304c\u306f\u305a\u308c\u305f\u3082\u306e\u3092\u6b8b\u3059\n",
        "my_result = tmp.sort_values('y_prob', ascending=False) # \u78ba\u7387\u306e\u5927\u304d\u3044\u9806\u306b\u4e26\u3073\u66ff\u3048\u308b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result.head()\n",
        "#>         y_prob  y_  y    id\n",
        "#> 2654  0.999997   1  6  2654\n",
        "#> 1232  0.999988   4  9  1232\n",
        "#> 3520  0.999926   4  6  3520\n",
        "#> 9729  0.999881   6  5  9729\n",
        "#> 2896  0.999765   0  8  2896"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    ans = my_result['y'].iloc[i]\n",
        "    id = my_result['id'].iloc[i]\n",
        "    plt.title(f'{ans} ({id})')\n",
        "    plt.imshow(x_test[id])\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h2o\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from h2o.automl import H2OAutoML\n",
        "from random import sample\n",
        "\n",
        "h2o.init()\n",
        "h2o.no_progress()\n",
        "# h2o.cluster().shutdown() # \u505c\u6b62"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
        "          '/fromzero/master/data/wine.csv')\n",
        "my_data = pd.read_csv(my_url)\n",
        "my_frame = h2o.H2OFrame(my_data) # \u901a\u5e38\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092H2OFrame\u306b\u5909\u63db\u3059\u308b\uff0e\n",
        "# \u3042\u308b\u3044\u306f\n",
        "my_frame = h2o.import_file(my_url, header=1) # \u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\uff0e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_frame.head(5)\n",
        "#>   LPRICE2    WRAIN    DEGREES  ...\n",
        "#> ---------  -------  ---------  ...\n",
        "#>  -0.99868      600    17.1167  ...\n",
        "#>  -0.4544       690    16.7333  ...\n",
        "#>  -0.80796      502    17.15    ...\n",
        "#>  -1.50926      420    16.1333  ...\n",
        "#>  -1.71655      582    16.4167  ...\n",
        "\n",
        "# \u901a\u5e38\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u306b\u623b\u3059\uff0e\n",
        "h2o.as_list(my_frame).head()\n",
        "# \u7d50\u679c\u306f\u5272\u611b\uff08\u898b\u305f\u76ee\u306f\u540c\u3058\uff09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = H2OAutoML(\n",
        "    max_runtime_secs=60)\n",
        "my_model.train(\n",
        "    y='LPRICE2',\n",
        "    training_frame=my_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.leaderboard['rmse'].min()\n",
        "#> 0.2704643402377778"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = h2o.as_list(\n",
        "    my_model.predict(my_frame))\n",
        "\n",
        "pd.DataFrame({\n",
        "    'y': my_data['LPRICE2'],\n",
        "    'y_': tmp['predict']}\n",
        ").plot('y', 'y_', kind='scatter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "my_index = sample(range(60000), 6000)\n",
        "x_train = x_train[my_index, :, :]\n",
        "y_train = y_train[my_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame(\n",
        "    x_train.reshape(-1, 28 * 28))\n",
        "y = 'y'\n",
        "tmp[y] = y_train\n",
        "my_train = h2o.H2OFrame(tmp)\n",
        "my_train[y] = my_train[y].asfactor()\n",
        "\n",
        "tmp = pd.DataFrame(\n",
        "    x_test.reshape(-1, 28 * 28))\n",
        "my_test = h2o.H2OFrame(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = H2OAutoML(\n",
        "    max_runtime_secs=120)\n",
        "my_model.train(\n",
        "    y=y,\n",
        "    training_frame=my_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.leaderboard[\n",
        "    'mean_per_class_error'].min()\n",
        "#> 0.06803754348177862"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = h2o.as_list(\n",
        "    my_model.predict(my_test))\n",
        "y_ = tmp.predict\n",
        "\n",
        "(y_ == y_test).mean()\n",
        "#> 0.938"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.to_datetime('2020-01-01')\n",
        "#> Timestamp('2020-01-01 00:00:00')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.date_range(start='2021-01-01', end='2023-01-01', freq='1A')\n",
        "#> DatetimeIndex(['2021-12-31', '2022-12-31'],\n",
        "#>               dtype='datetime64[ns]', freq='A-DEC')\n",
        "\n",
        "pd.date_range(start='2021-01-01', end='2023-01-01', freq='1AS')\n",
        "#> DatetimeIndex(['2021-01-01', '2022-01-01', '2023-01-01'],\n",
        "#>               dtype='datetime64[ns]', freq='AS-JAN')\n",
        "\n",
        "pd.date_range(start='2021-01-01', end='2021-03-01', freq='2M')\n",
        "#> DatetimeIndex(['2021-01-31'], dtype='datetime64[ns]', freq='2M')\n",
        "\n",
        "pd.date_range(start='2021-01-01', end='2021-03-01', freq='2MS')\n",
        "#> DatetimeIndex(['2021-01-01', '2021-03-01'],\n",
        "#>               dtype='datetime64[ns]', freq='2MS')\n",
        "\n",
        "pd.date_range(start='2021-01-01', end='2021-01-03', freq='1D')\n",
        "#> DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03'],\n",
        "#>               dtype='datetime64[ns]', freq='D')\n",
        "\n",
        "pd.date_range(start='2021-01-01 00:00:00', end='2021-01-01 03:00:00', freq='2H')\n",
        "#> DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 02:00:00'],\n",
        "#>               dtype='datetime64[ns]', freq='2H')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pmdarima.datasets import airpassengers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "my_data = airpassengers.load_airpassengers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = len(my_data) # \u30c7\u30fc\u30bf\u6570\uff08144\uff09\n",
        "k = 108          # \u8a13\u7df4\u30c7\u30fc\u30bf\u6570"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_ds = pd.date_range(\n",
        "    start='1949/01/01',\n",
        "    end='1960/12/01',\n",
        "    freq='MS')\n",
        "my_df = pd.DataFrame({\n",
        "    'ds': my_ds,\n",
        "    'x': range(n),\n",
        "    'y': my_data},\n",
        "    index=my_ds)\n",
        "my_df.head()\n",
        "#>                    ds  x      y\n",
        "#> 1949-01-01 1949-01-01  0  112.0\n",
        "#> 1949-02-01 1949-02-01  1  118.0\n",
        "#> 1949-03-01 1949-03-01  2  132.0\n",
        "#> 1949-04-01 1949-04-01  3  129.0\n",
        "#> 1949-05-01 1949-05-01  4  121.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_train = my_df[        :k]\n",
        "my_test  = my_df[-(n - k): ]\n",
        "y = my_test.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_train.y, label='train')\n",
        "plt.plot(my_test.y,  label='test')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "my_lm_model = LinearRegression()\n",
        "my_lm_model.fit(my_train[['x']], my_train.y)\n",
        "\n",
        "X = my_test[['x']]\n",
        "y_ = my_lm_model.predict(X)\n",
        "mean_squared_error(y, y_)**0.5 # RMSE\uff08\u30c6\u30b9\u30c8\uff09\n",
        "#> 70.63707081783771"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = my_lm_model.predict(my_df[['x']])\n",
        "tmp = pd.DataFrame(y_,\n",
        "                   index=my_df.index)\n",
        "plt.plot(my_train.y, label='train')\n",
        "plt.plot(my_test.y,  label='test')\n",
        "plt.plot(tmp, label='model')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pmdarima as pm\n",
        "my_arima_model = pm.auto_arima(my_train.y, m=12, trace=True)\n",
        "#> \uff08\u7701\u7565\uff09\n",
        "#> Best model:  ARIMA(1,1,0)(0,1,0)[12]\n",
        "#> Total fit time: 0.838 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_, my_ci = my_arima_model.predict(len(my_test),         # \u671f\u9593\u306f\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u540c\u3058\uff0e\n",
        "                                   alpha=0.05,           # \u6709\u610f\u6c34\u6e96\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\n",
        "                                   return_conf_int=True) # \u4fe1\u983c\u533a\u9593\u3092\u6c42\u3081\u308b\uff0e\n",
        "tmp = pd.DataFrame({'y': y_,\n",
        "                    'Lo': my_ci[:, 0],\n",
        "                    'Hi': my_ci[:, 1]},\n",
        "                   index=my_test.index)\n",
        "tmp.head()\n",
        "#>                      y          Lo          Hi\n",
        "#> 1958-01-01  345.964471  327.088699  364.840243\n",
        "#> 1958-02-01  331.731920  308.036230  355.427610\n",
        "#> 1958-03-01  386.787992  358.515741  415.060244\n",
        "#> 1958-04-01  378.774472  346.695454  410.853490\n",
        "#> 1958-05-01  385.777732  350.270765  421.284700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_squared_error(y, y_)**0.5\n",
        "#> 22.132236727738697"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(my_train.y, label='train')\n",
        "plt.plot(my_test.y,  label='test')\n",
        "plt.plot(tmp.y,      label='model')\n",
        "plt.fill_between(tmp.index,\n",
        "                 tmp.Lo,\n",
        "                 tmp.Hi,\n",
        "                 alpha=0.25) # \u4e0d\u900f\u660e\u5ea6\n",
        "plt.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try: from fbprophet import Prophet\n",
        "except ImportError: from prophet import Prophet\n",
        "my_prophet_model = Prophet(seasonality_mode='multiplicative')\n",
        "my_prophet_model.fit(my_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_prophet_model.predict(my_test)\n",
        "tmp[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()\n",
        "#>           ds        yhat  yhat_lower  yhat_upper\n",
        "#> 0 1958-01-01  359.239305  350.910898  368.464588\n",
        "#> 1 1958-02-01  350.690546  341.748862  359.964881\n",
        "#> 2 1958-03-01  407.188556  398.483316  415.463759\n",
        "#> 3 1958-04-01  398.481739  389.244105  406.742333\n",
        "#> 4 1958-05-01  402.595604  393.721421  411.331761"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ = tmp.yhat\n",
        "mean_squared_error(y, y_)**0.5\n",
        "#> 33.795549086036466"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# my_prophet_model.plot(tmp) # \u4e88\u6e2c\u7d50\u679c\u306e\u307f\u3067\u3088\u3044\u5834\u5408\n",
        "\n",
        "fig = my_prophet_model.plot(tmp)\n",
        "fig.axes[0].plot(my_train.ds, my_train.y)\n",
        "fig.axes[0].plot(my_test.ds, my_test.y, color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pca import pca\n",
        "from scipy.stats import zscore\n",
        "\n",
        "my_data = pd.DataFrame(\n",
        "    {'language': [  0,  20,  20,  25,  22,  17],\n",
        "     'english':  [  0,  20,  40,  20,  24,  18],\n",
        "     'math':     [100,  20,   5,  30,  17,  25],\n",
        "     'science':  [  0,  20,   5,  25,  16,  23],\n",
        "     'society':  [  0,  20,  30,   0,  21,  17]},\n",
        "    index=       ['A', 'B', 'C', 'D', 'E', 'F'])\n",
        "my_model = pca(n_components=5)\n",
        "my_result = my_model.fit_transform(my_data) # \u4e3b\u6210\u5206\u5206\u6790\u306e\u5b9f\u884c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result['PC'] # \u4e3b\u6210\u5206\u30b9\u30b3\u30a2\n",
        "#>          PC1        PC2 ...\n",
        "#> A  74.907282   7.010808 ...\n",
        "#> B -13.818842  -2.753459 ...\n",
        "#> C -33.714034  18.417290 ...\n",
        "#> D  -1.730630 -17.876372 ...\n",
        "#> E -17.837474   1.064998 ...\n",
        "#> F  -7.806303  -5.863266 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model.biplot(legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result['loadings']\n",
        "#>      language   english      math   science   society\n",
        "#> PC1 -0.207498 -0.304360  0.887261 -0.130198 -0.245204\n",
        "#> PC2 -0.279463  0.325052  0.097643 -0.702667  0.559435\n",
        "#> PC3  0.306117  0.615799  0.056345 -0.338446 -0.639815\n",
        "#> PC4  0.764943 -0.471697 -0.007655 -0.418045  0.132455\n",
        "#> PC5 -0.447214 -0.447214 -0.447214 -0.447214 -0.447214"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result['explained_var']\n",
        "#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = zscore(my_data, ddof=1) # \u6a19\u6e96\u5316\n",
        "my_result = my_model.fit_transform(\n",
        "    tmp)\n",
        "my_result['PC'] # \u4e3b\u6210\u5206\u30b9\u30b3\u30a2\n",
        "#>           PC1       PC2 ...\n",
        "#> 1.0  3.673722  0.568850 ...\n",
        "#> 1.0 -0.652879 -0.246926 ...\n",
        "#> 1.0 -1.568294  1.742598 ...\n",
        "#> 1.0 -0.250504 -1.640039 ...\n",
        "#> 1.0 -0.886186  0.110493 ...\n",
        "#> 1.0 -0.315858 -0.534976 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = my_data - my_data.mean()\n",
        "Z  = np.matrix(tmp)                       # \u6a19\u6e96\u5316\u3057\u306a\u3044\u5834\u5408\n",
        "#Z = np.matrix(tmp / my_data.std(ddof=1)) # \u221a\u4e0d\u504f\u5206\u6563\u3067\u6a19\u6e96\u5316\u3059\u308b\u5834\u5408\n",
        "#Z = np.matrix(tmp / my_data.std(ddof=0)) # pca(normalize=True)\u306b\u5408\u308f\u305b\u308b\u5834\u5408\n",
        "\n",
        "n = len(my_data)\n",
        "S = np.cov(Z, rowvar=0, ddof=0)      # \u5206\u6563\u5171\u5206\u6563\u884c\u5217\n",
        "#S = Z.T @ Z / n                     # \uff08\u540c\u3058\u7d50\u679c\uff09\n",
        "vals, vecs = np.linalg.eig(S)        # \u56fa\u6709\u5024\u3068\u56fa\u6709\u30d9\u30af\u30c8\u30eb\n",
        "idx = np.argsort(-vals)              # \u56fa\u6709\u5024\u306e\u5927\u304d\u3044\u9806\u306e\u756a\u53f7\n",
        "vals, vecs = vals[idx], vecs[:, idx] # \u56fa\u6709\u5024\u306e\u5927\u304d\u3044\u9806\u3067\u306e\u4e26\u3079\u66ff\u3048\n",
        "Z @ vecs                             # \u4e3b\u6210\u5206\u30b9\u30b3\u30a2\uff08\u7d50\u679c\u306f\u5272\u611b\uff09\n",
        "vals.cumsum() / vals.sum()           # \u7d2f\u7a4d\u5bc4\u4e0e\u7387\n",
        "#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "U, d, V =  np.linalg.svd(Z, full_matrices=False)     # \u7279\u7570\u5024\u5206\u89e3\n",
        "W = np.diag(d)\n",
        "\n",
        "[np.isclose(Z, U @ W @ V).all(),                     # \u78ba\u8a8d1\n",
        " np.isclose(U.T @ U, np.identity(U.shape[1])).all(), # \u78ba\u8a8d2\n",
        " np.isclose(V @ V.T, np.identity(V.shape[0])).all()] # \u78ba\u8a8d3\n",
        "#> [True, True, True]\n",
        "\n",
        "U @ W                # \u4e3b\u6210\u5206\u30b9\u30b3\u30a2\uff08\u7d50\u679c\u306f\u5272\u611b\uff09\n",
        "\n",
        "e = d ** 2 / n       # \u5206\u6563\u5171\u5206\u6563\u884c\u5217\u306e\u56fa\u6709\u5024\n",
        "e.cumsum() / e.sum() # \u7d2f\u7a4d\u5bc4\u4e0e\u7387\n",
        "#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.cluster import hierarchy\n",
        "\n",
        "my_data = pd.DataFrame(\n",
        "    {'x': [  0, -16,  10,  10],\n",
        "     'y': [  0,   0,  10, -15]},\n",
        "    index=['A', 'B', 'C', 'D'])\n",
        "\n",
        "my_result = hierarchy.linkage(\n",
        "    my_data,\n",
        "    metric='euclidean', # \u7701\u7565\u53ef\n",
        "    method='complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hierarchy.dendrogram(my_result,\n",
        "    labels=my_data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hierarchy.cut_tree(my_result, 3)\n",
        "#> array([[0], [1], [0], [2]])\n",
        "\n",
        "# \u88dc\u8db3\uff08\u898b\u3084\u3059\u304f\u3059\u308b\uff09\n",
        "my_data.assign(cluster=\n",
        "  hierarchy.cut_tree(my_result, 3))\n",
        "#>     x   y  cluster\n",
        "#> A   0   0        0\n",
        "#> B -16   0        1\n",
        "#> C  10  10        0\n",
        "#> D  10 -15        2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "my_data = pd.DataFrame(\n",
        "    {'language': [  0,  20,  20,  25,  22,  17],\n",
        "     'english':  [  0,  20,  40,  20,  24,  18],\n",
        "     'math':     [100,  20,   5,  30,  17,  25],\n",
        "     'science':  [  0,  20,   5,  25,  16,  23],\n",
        "     'society':  [  0,  20,  30,   0,  21,  17]},\n",
        "    index=       ['A', 'B', 'C', 'D', 'E', 'F'])\n",
        "\n",
        "sns.clustermap(my_data, z_score=1) # \u5217\u3054\u3068\u306e\u6a19\u6e96\u5316"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "my_data = pd.DataFrame(\n",
        "    {'x': [  0, -16,  10,  10],\n",
        "     'y': [  0,   0,  10, -15]},\n",
        "    index=['A', 'B', 'C', 'D'])\n",
        "\n",
        "my_result = KMeans(\n",
        "    n_clusters=3).fit(my_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result.labels_\n",
        "#> array([1, 0, 1, 2], dtype=int32)\n",
        "\n",
        "# \u88dc\u8db3\uff08\u898b\u3084\u3059\u304f\u3059\u308b\uff09\n",
        "my_data.assign(\n",
        "  cluster=my_result.labels_)\n",
        "#>     x   y  cluster\n",
        "#> A   0   0        1\n",
        "#> B -16   0        0\n",
        "#> C  10  10        1\n",
        "#> D  10 -15        2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "iris = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "my_data = iris.iloc[:, 0:4]\n",
        "\n",
        "k = range(1, 11)\n",
        "my_df = pd.DataFrame({\n",
        "    'k': k,\n",
        "    'inertia': [KMeans(k).fit(my_data).inertia_ for k in range(1, 11)]})\n",
        "my_df.plot(x='k', style='o-', legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from pca import pca\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.stats import zscore\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "iris = sm.datasets.get_rdataset('iris', 'datasets').data\n",
        "my_data = zscore(iris.iloc[:, 0:4])\n",
        "\n",
        "my_model = pca() # \u4e3b\u6210\u5206\u5206\u6790\n",
        "my_result = my_model.fit_transform(my_data)['PC']\n",
        "my_result['Species'] = list(iris.Species)\n",
        "\n",
        "# \u975e\u968e\u5c64\u7684\u30af\u30e9\u30b9\u30bf\u5206\u6790\u306e\u5834\u5408\n",
        "my_result['cluster'] = KMeans(n_clusters=3).fit(my_data).labels_\n",
        "\n",
        "# \u968e\u5c64\u7684\u30af\u30e9\u30b9\u30bf\u5206\u6790\u306e\u5834\u5408\n",
        "#my_result['cluster'] = hierarchy.cut_tree(\n",
        "#    hierarchy.linkage(my_data, method='complete'), 3)[:,0]\n",
        "\n",
        "sns.scatterplot(x='PC1', y='PC2', data=my_result, legend=False,\n",
        "                hue='cluster',   # \u8272\u3067\u30af\u30e9\u30b9\u30bf\u3092\u8868\u73fe\u3059\u308b\uff0e\n",
        "                style='Species', # \u5f62\u3067\u54c1\u7a2e\u3092\u8868\u73fe\u3059\u308b\uff0e\n",
        "                palette='bright')"
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}